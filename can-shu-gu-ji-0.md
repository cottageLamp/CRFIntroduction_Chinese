# 5.参数估计

这一节，我们讲述如何估计CRF的参数$$\theta=\{\theta_k\}$$。在最典型、最简单的情况下，数据是完全标注的，但也有研究是关于半监督CRF、带隐藏变量的CRF和关系学习的CRF。

极大似然是一种训练CRF的方法，就是说，要选择参数，使训练数据在模型意义下具有最高的概率。原理上，它与逻辑回归的做法很像。考虑我们在第2节所讲述的这些模型之间的联系，这一点应该不让人意外。主要的区别点在于计算方面：CRF倾向拥有更多参数、更复杂的结构，导致了更高的训练成本。

在树形CRF中，极大似然可基于数值优化过程，以第4.1节江苏的推断算法为子过程。推断算法同时计算了似然和它的梯度。一般来说，似然是关于参数的凸函数，意味着有效的优化过程是现成的，且一定收敛到最优点。

我们从讲述极大似然开始，包含有线性链（第5.1.1节）和通用图结构（第5.1.2节），还包括隐藏变量的情况。我们也将讲述两种加快参数训练的方法：随机梯度下降法（挖掘数据中的 iid 结构，第5.2节）和多线程训练（第5.3节）。

对于通用CRF，精确的极大似然训练是不存在的，因而需要近似过程。泛泛地说，有两种解决问题的策略。一是使用易于计算的函数来近似该似然，叫做**代理似然surrogate likelihood**，再数值地优化该代理函数。第二种方法是边缘概率近似。它在极大似然训练需要精确计算的时候，嵌入一个近似的推断算法来计算边缘分布。这里需要小心，因为近似推断和学习之间存在着微妙而复杂的作用。我们在第5.4节讨论这些。