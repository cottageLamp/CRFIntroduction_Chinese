# 4 推断

推断的效率对CRFs至关重要，无论是对训练还是预测。有两个关于推断的任务。一是给定新的输入x后，要预测最可能的输出$$y^*=\arg\max_{y}p(y|x)$$。二是，正如第5节所述，参数估计时所需的边缘分布，如单个节点的$$p(y_t|x)$$和连接的$$p(y_t,y_{t-1}|x)$$。这两个任务可被看成two different smirings下的同一操作。就是说，把边缘概率问题改成求最大值问题，我们只需简单地把求和运算变成求最大运算。

对于离散的情况，可通过穷举的办法计算边缘概率，然而所需的计算时间会因Y的尺寸而指数爆炸。实际上，对于通用图来说，关于推断的两个问题都是困难的，因为任何*命题可满足性问题propositional satisfiability problem*都可以轻易地用因子图来表示。

可快速而精确地解线性链CRFs，其方法是HMMs的动态规划算法的变体。在第4.1节，我们从计算边缘分布的forward-backward算法以及计算最可能赋值的Viterbi算法开始。这些算法那是通用的置信传播算法belief propagation algorithm在树图模型(4.2.2)上的特例。对于更复杂的模型，需要近似的推断算法。

可以说，CRF的推断问题与一般的图模型并无差别，因而一般图模型的推断算法也都适用，如一些教材【57,59】所言。然而关于CRFs，我们需要时刻注意两点。第一，在参数估计(5.1.1)时需要反复执行推断任务，非常耗时，因而我们希望能在计算效率和准确性之间做些权衡。第二，若采用了近似推断，那可能会带来推断过程与训练过程之间复杂的相互作用。我们把这一议题延后至第5节，因为我们将在那里讨论参数估计，然而有必要在这里提出这个问题，因为它严重影响着对推断算法的选择。

## 4.1 线性链CRFs

这一节，我们简要介绍HMMs的标准推断算法——前向后向以及Viterbi算法，以及如何将它们应用在线性链CRFs上。Rabiner的【111】是一份关于这些算法在HMM上的研究。所有这些算法都只是第4.2.2节将要描述的置信传播算法的特例。然而，我们仍将详细讨论这一在线性链上的特例，因为它能让后面的讨论更具体，也因为它自身在工程上就很有用。

首先，我们引入一些记号，能简化接下来的前向后向递归(forward backward recursion)。一个HMM可以写成Z=1的因子图$$p(y,x)=\prod_t\Psi_t(y_t,y_{t-1},x_t)$$，而因子被定义为
$$
\Psi_t(j,t,x)\stackrel{def}{=}p(y_t=j|y_{t-1}=i)p(x_t=x|y_t=j) (4.1)
$$
如果把这个HMM看成带权重的有限状态机，那么$$\Psi_t(j,i,x)$$就是当观测为x时，从状态i变成j的权重。

现在我们来研究HMM的前向算法，这是用来计算观测值的概率p(x)的。前向后向算法背后的思想是，首先把$$p(x)=\sum_yp(x,y)$$的求和运算，按照如下的方式重写

$$
\begin{align}
p(x)=&\sum_y\prod^T_{t=1}\Psi_t(y_t,y_{t-1},x_t)
\end{align}
$$

$$
\begin{align}
=\sum_{y_T}\sum_{y_{T-1}}\Psi_T(y_T,y_{T-1},x_T)\sum_{y_{T-2}}\Psi_{T-1}(Y_{T-1},y_{T-2},x_{T-1})\sum_{y_{T-2}}\cdots\
(4.3)
\end{align}
$$
现在我们可以看到，在进行外部的求和运算时，其内部的求和运算要被反复调用。因此，我们可以把里面的保存起来，从而爆炸式地减少了计算量。

这导致了所谓的前向变量$$\alpha_t$$，是大小为M的向量(M是状态的数量)，用来保存求和的中间结果。其定义为：

$$
\begin{align}
\alpha_t(j)&\stackrel{def}{=}p(x_{<1\cdots t>},y_t=j)\\
&=\sum_{y_{<1\cdots t-1>}}\Psi_t(j,y_{t-1},x_t)\prod^{t-1}_{t'=1}\Psi_{t'}(y_{t'},y_{t'-1},x_{t'}) (4.5)
\end{align}
$$

其中，求和运算的下标$${y}_{1\cdots t-1}$$，表示要覆盖$$y_1,y_2,\cdots,y_{t-1}$$的所有可能值。这一alpha可以通过递归的方式计算

$$
\alpha_t(j)=\sum_{i\in S}\Psi_t(j,i,x_t)\alpha_{t-1}(i) (4.6)
$$

而初始变量为$$\alpha_1(j)=\Psi_1(j,y_0,x_1)$$。(回忆(2.10)，知道$$y_0$$是HMM的固定的初始值)。反复地递归(4.6)式，可知$$p(x)=\sum_{y_T}\alpha_T(y_T)$$。正式地证明应该需要数学归纳法。

后向递归于此相同，除了在(4.3)中把求和的顺序颠倒过来。所得的定义为

$$
\beta_t(i)&\stackrel{def}{=}p(x_{<t+1\cdots T>}|y_t=i)
$$

$$
=\sum_{y_{<t+1\cdots T>}}\prod^T_{t'=t+1}\Psi_{t'}(y_{t'},y_{t'-1},x_{t'}) (4.8)
$$

而其递归为

$$
\beta_t(i)=\sum_{j\in S}\Psi_{t+1}(j,i,x_{t+1})\beta_{t+1}(j) (4.9)
$$

其中，初始量为$$\beta_T(i)=1$$。与前向类似，我们也可以用后向变量来计算$$p(x)=\beta_0(y_0)\stackrel{def}{=}\sum_{y_1}\Psi_1(y_1,y_0,x_1)\beta_1(y_1)$$。

要计算边缘分布$$p(y_{t-1},y_t|x)$$(在参数估计时需要)，我们要把前向和后向的结果综合起来。这可以从概率或因子分解的角度来看。首先，从概率的角度来看，我们写成

$$
p(y_{t-1},y_t|x)=\frac{p(x|y_{t-1},y_t)p(y_{t-1},y_t)}{p(x)}
$$

$$
=\frac{p(x_{<1\cdots t-1>},y_{t-1})p(y_t|y_{t-1})p(x_t|y_t)p(x_{<t+1\cdots T}|y_t)}{p(x)}
$$

$$
=\frac{1}{p(x)}\alpha_{t-1}\Psi_t(y_t,y_{t-1},x_t)\beta_t(y_t) (4.12)
$$

在上式的第二行中，我们基于如下的事实：给定$$y_t,y_{t-1}$$后，$$x_{<1\cdots t-1>}$$与$$x_{<t+1\cdots T>}$$以及$$x_t$$无关。同样的，从因子分解的角度看，我们利用分配率得

$$
p(y_{t-1},y_t|x)=\frac{1}{p(x)}\Psi_t(y_t,y_{t-1},x_t)
$$

$$
\times \left(\sum_{y_{<1\cdots t-2>}}\prod^{t-1}_{t'=1}\Psi_{t'}(y_{t'},y_{t'-1},x_{t'})\right)
$$

$$
\times \left(\sum_{y_{<t+1\cdots T>}}\prod^{T}_{t'=t+1}\Psi_{t'}(y_{t'},y_{t'-1},x_{t'})\right)
$$

然后，通过带入$$\alpha$$与$$\beta$$的定义，我们得到与前文一样的结果，即：

$$
p(y_{t-1},y_t|x)=\frac{1}{p(x)}\alpha_{t-1}(y_{t-1})\Psi_t(y_t,y_{t-1},x_t)\beta_t(y_t) (4.14)
$$

而$$1/p(x)$$相当于分布的归一化常数。我们通过$$p(x)=\beta_0(y_0)$$或$$p(x)=\sum_{i\in S}\alpha_T(i)$$来计算它。

总的来说，前向后向算法就是：首先用(4.6)计算每个$$\alpha_t$$，然后用(4.9)计算每个$$\beta_t$$，然后用(4.14)计算边缘分布。

最后，如要计算最可能的输出$$y^*=\arg\max_{y}p(y|x)$$，我们发现之前在(4.3)中使用的技巧仍然有效。这带来了Viterbi算法。与前向变量$$\alpha$$像类似的变量为

$$
\delta_t(j)\stackrel{def}{=}\max_{y_{<1\cdots t-1>}}\Psi_t(j,y_{t-1},x_t)\prod^{t-1}_{t'=1}\Psi_{t'}(y_{t'},y_{t'-1},x_{t'}) (4.15)
$$

而这可以通过类似的递归来计算:

$$
\delta_t(j)=\max_{i\in S}\Psi_t(j,i,x_t)\delta_{t-1}(i) (4.16)
$$

$$\delta$$被计算出来之后，最可能的输出可通过如下的后向递归计算:

$$
y_T^*=\arg\max_{i\in S}\delta_T(i)
$$

$$
y_t^*=\arg\max_{i\in S}\Psi_t(y^*_{t+1},i,x_{t+1})\delta_t(i)\ for\ t<T
$$

对$$\delta_t$$和$$y^*_t$$的递归，构成了**Viterbi算法**。

现在，我们已经讲述了HMMs的前向后向和Viterbi算法。将其扩展到线性链CRFs是直接的。线性链CRFs的前向后向算法与HMMs的一样，只是转移权重$$\Psi_t(j,i,x_t)$$的定义需要改变。我们注意到，(2.18)的CRF模型可以重写为

$$
p(y|x)=\frac{1}{Z(x)}\prod^T_{t=1}\Psi_t(y_t,y_{t-1},x_t),(4.17)
$$

其中

$$
\Psi_t(y_t,y_{t-1},x_t)=exp\left\{\sum_k\theta_k f_k(y_t,y_{t-1},x_t)\right\} (4.18)
$$

使用这里的定义，前向递归(4.6)、后向递归(4.9)以及Viterbi递归(4.16)可不经过修改就用于线性链CRFs，只是其含义有所改变。在CRF中，$$\alpha_t(j)=p(x_{<1\cdots t>},y_t=j)$$不再具有概率的含义，而需从因子分解的角度来理解。就是说，我们需根据(4.5)定义$$\alpha$$，(4.8)定义$$\beta$$，(4.15)定义$$\delta$$。同样地，前向后向递归的结果现在变成了Z(x)，而不是p(x)，且$$Z(x)=\beta_0(y_0),Z(x)=\sum_{i\in S}\alpha_T(i)$$。

关于边缘分布，方程(4.14)仍然有效，只是需用Z(x)替换p(x)，即

$$
p(y_{t-1},y_t|x)=\frac{1}{Z(x)}\alpha_{t-1}(y_{t-1})\Psi_t(y_t,y_{t-1},x_t)\beta_t(y_t) (4.19)
$$

$$
p(y_t|x)=\frac{1}{Z(x)}\alpha_t(y_t)\beta_t(y_t) (4.20)
$$

我们补充三个可被上面的算法直接解的推断任务。一，如果我们想从后验概p(y|x)中采样y，可使用前向算法+后向采样过程，就如在HMMs中的做法一样。二，如果不想只找到唯一的最可能输出$$\arg\max_{y}p(y|x)$$，而是前k个可能输出，我们可以使用HMMs的标准算法[129]。最后，有时候我们要计算一组节点$$S\subset[1,2,\cdots,T]$$(不一定是连接在一起的)的边缘概率$$p({y_S|x})$$。例如，这可用于评估模型在部分输入上的性能。这一边缘概率可使用Culotta和McCallum【30】描述的带约束前向后向算法来解。

## 4.2 图模型的推断

通用图模型的精确推断算法也有不少。最槽糕的时候，它们需要指数级别的耗时，但在工程实践中扔不失为有效的方法。最流行的精确算法是联和树算法。它连续地把变量组合起来，使整个图变成一棵树。一旦这棵等效树被建立了起来，我们就可以用已有的、针对树的精确推断算法了。然而对于某些复杂的图，联合树算法需要做规模巨大的聚类，使它在最槽糕时仍需要指数级别的计算时间。关于精确算法的更多细节，请参考Koller和Friedman【57】。

由于精确推断的复杂性，大量的努力朝向了近似推断算法。有两类近似算法获得了最多的关注：蒙特卡洛算法和变分法。蒙特卡洛算法是统计算法，尝试从分布中近似地产生样本。变分法把推断问题转变成最优化问题，然后尝试找到边缘概率的最近的估计。一般来说，只要给与足够的时间，蒙特卡洛算法总能无偏地从分布中进行采样，但在实践中一般无法知道何时做到了这一点。变分法非常快速，但倾向于偏差，就是说，它天生具有一些误差，且哪怕拥有足够的计算时间也不能消除。尽管如此，变分法对CRFs是有用的。因为参数估计需要多次执行推断，所以快速的推断对于高效地训练十分关键。关于蒙特卡洛算法，可参考Robert和Casella【116】。对于变分方法，可参考Wainwright和Jordan【150】。

从两个方面，本节的内容特别针对CRFs，但也适用于从某些因子图得来的任何分布，不管它是联合分布p(y)，还是像CRFs的条件分布p(y|x)。为了强调这一点，也为了简化记号，我们去掉了对x的依赖，而只讨论联合分布p(y)的推断。该分布从某些因子图G=(V,F)而来，即

$$
p({y})=Z^{-1}\prod_{a\in F}\Psi_a({y}_a).
$$

若想将这里的讨论用于CRFs，只需用$$\Psi_a(y_a,x_a)$$替换上面的$$\Psi_a(y_a)$$，同时将$$Z$$换成p(y)。这样就可以对x依赖了。这不仅是记号的问题，还会影响到具体的实践：推断算法可实现成适用于一般的因子图，而无需知道它是无向的联合分布p(y)，还是CRF 的p(y|x)，或甚至是有向的图模型。

在本节的剩余部分，我们扼要地介绍近似推断算法的两个例子，分别来自两个大类。我们不能在这里包含所有的 近似推断算法。相反地，我们的目标是想强调近似推断算法给CRF的训练带来的一般性问题。本节中，我们关注推断算法本身，而在第5节介绍它们在CRFs中的应用。

### 4.2.1马尔科夫链蒙特卡洛

当前最流行的复杂模型的蒙特卡洛方法是马尔科夫链蒙特卡洛 (MCMC)【116】。它不去直接估计边缘概率$$p(y_s)$$，而是从联合分布p(y)中产生估计样本。MCMC方法通过构造一个马尔科夫链，使其状态空间与$$Y$$相同，小心地用该链做仿真足够长的时间，使得链的状态分布接近$$p(y_s)$$。假如函数f(y)服从分布p(y)，而我们想估计它的期望。给定MCMC方法的马尔科夫链的一组样本$${y}^1,{y}^2,\cdots,{y^M}$$，我们可以通过下式来估计这个期望

$$
\sum_{y}p(y)f(y)\approx \frac{1}{M}\sum^M_{j=1}f(y^j) (4.21)
$$

下一节我们将发现，CRF的训练需要这一形式的期望。
MCMC方法的一个简单例子是Gibbs采样。在Gibbs算法的每个迭代周期里，每个变量独立地被重采样而保持其他变量不变。假如我们已经在第j次采样获得了样本$$y^j$$，那么需要产生下一个样本$$y^{j+1}$$
(1)取$$y^{j+1}= y^j$$。
(2)对每个$$s\in S$$，重采样$$Y_s$$。从分布$$p(y_s|{y}_{\backslash s}, x)$$中采样$$y^{j+1}_s$$。
(3)返回$$y^{j+1}$$作为结果。

回忆一下地2.1.1节，$$\sum_{y\backslash y_s}$$表示求和运算要遍历$$ y$$的所有可能取值，除了$$Y_s$$取值$$y_s$$。

上面的过程定义了一个马尔科夫链，可用于近似式(4.21)的期望。对于通用因子图，条件概率可按照下式计算

$$
p(y_s|y_{\backslash s})=\kappa \prod_{a\in F} \Psi_a(y_a),(4.22)
$$

其中，$$\kappa$$是归一化常量。(下文中，$$\kappa$$是一般意义的归一化常量，不要求在不同的式子中取相同的值)。式(4.22)的$$\kappa$$要比联合概率p(y|x)容易计算得多，因为它只需遍历$$y_s$$的所有可能取值，而不是整个y向量。

Gibbs的一个主要优点是它易于实现。实际上，像BUGS这种软件包允许以图模型作为输入，自动编译一个Gibbs取样器用于近似【78】。Gibbs的主要缺点是，当p( y)存在强相关时，Gibbs性能较差，而这在序列形式的数据中很常见。关于性能较差，我们的意思是，它需要很多次迭代才能让马尔科夫链的样本接近于所需的分布p(y)。

有大量的关于MCMC算法的文献。Robert和Casella的教材【116】提供了一个综述。然而，CRFs领域却不常用MCMC算法。原因可能正如我们说过的，极大似然方法做参数估计时，需要计算边缘概率很多次。不考虑复杂的策略，那么每次梯度下降时，都要为每一个参数集的每一个训练样本运行一次MCMC链。而MCMC链自身就需要千把次迭代才能收敛，使得这种方法在计算上难以实行。读者可能想到了一些解决办法，比如不等马尔科夫链收敛就返回(参考地5.4.3节)。

### 4.2.2 置信传播

**置信传播belief propagation(BP)**是一种重要的变分推断算法<font color=red>variational inference algorithm 翻译成变分推断算法似乎不合适。这里似乎只是“变体“的含义，把推断问题变成优化问题。</font>我们将在本节解释它。BP同时还是线性链CRFs的精确推断算法的一般化。

假如因子图G=(V,F)是一棵树，而我们希望计算变量$$Y_s$$的边缘概率。BP背后的思想在于，它认为每个与$$Y_s$$相连的因子按照乘法来提供边缘概率，我们称它们为**信息message**。因为图是一棵树，所以每个信息可被单独计算。更正式地，对每个因子$$a\in N(s)$$，记$$G_a=(V_a,F_a)$$为包含$$Y_s、\Psi_a$$以其$$\Psi_a$$全部"上游"的G的子图。所谓的“上游”，我们指$$V_a$$包含了所有被$$\Psi_a$$隔开，从而与$$Y_s$$分离的变量，以及从而与$$F_a$$分离的因子。参见图4.1。对于每个$$a\in N(s)$$，每个$$V_a\backslash Y_s$$相互独立，因为G是一棵树。对$$F_a$$亦如此。这意味着，我们可以把边缘概率所需的求和运算划分成多个独立的子问题相乘，即

$$
p(y_s)\propto \sum_{ y\backslash {y_s}}\prod_{a\in F}\Psi_a(y_a) (4.21)
$$

$$
=\sum_{ y\backslash {y_s}}\prod_{a\in N(s)}\prod_{\Psi_b\in F_a}\Psi_b({y}_b) (4.24)
$$

$$
=\prod_{a\in N(s)}\sum_{ y_{V_a}\backslash {y_s}}\prod_{\Psi_b\in F_a}\Psi_b({y}_b) (4.25)
$$

虽然上面的记号不够明显，但需注意变量$$y_s$$包含在每个$$y_a$$中，所以它在(4.25)的两边都出现了。

![](/assets/4.1.png)

图4.1 树形图的边缘分布是如何被划分的。这一划分被置信传播算法(4.2.2)所用。

把上式的每个因子记为$$m_{as}$$，那么

$$
m_{as}(y_s)=\sum_{y_{V_a}\backslash y_s}\prod_{\Psi_b\in F_a}\Psi_b(y_b) (4.26)
$$

每个$$m_{as}$$正是从子图$$G_a$$过来的关于变量的$$y_s$$的边缘分布。$$y_s$$在全图上的边缘分布，正是每个子图上的边缘分布的乘积。这就好比$$m_{as}(y_s)$$是因子$$a$$传给$$Y_s$$的**信息message**，而这一信息汇合$$a$$上游的全部作用。同样地，我们可定义从变量到因子的信息:

$$
m_{sa}(y_s)=\sum_{ y_{V_a}}\prod_{\Psi_b\in F_s}\Psi_b(y_b) (4.27)
$$

然后考虑(4.25)式，我们知道边缘概率$$p(y_s)$$与所有到达$$Y_s$$的消息的乘积成比例。同样地，因子的边缘概率可计算为：

$$
p( y_a)\propto \Psi_a(y_a)\prod_{s\in N(a)}m_{sa}(y_a) (4.28)
$$

直接按照(4.26)式计算消息还不行，因为需要遍历$$y_{V_a}$$的所有可能取值来进行求和运算，而有时$$V_a$$是很大的集合。幸运的是，消息也可被写成递归的形式，从而只需局部的求和。递归形式是：

$$
m_{as}(y_s)=\sum_{ y_a\backslash y_s}\Psi_a( y_a)\prod_{t\in a\backslash s}m_{ta}(y_t)
$$

$$
m_{sa}(y_s)=\prod_{b\in N(s)\backslash a}m_{bs}(y_s). (4.29)
$$

通过依次带入，可知这一递归形式符合$$m$$的定义，也可通过数学归纳法证明。对于树形图，有可能通过合理的安排，使得每个消息被发送之前已收到它所依赖的上游消息，比如首先从根开始发送消息。这就是置信传播算法【103】。

除了计算单个变量的边缘概率，我们也希望计算银子的概率$$p(y_a)$$和联合概率$$p(y)$$。(回忆一下，后面这个任务是困难的，因为要计算归一化函数$$\log Z$$)。首先，我们可以像单个变量那样解构，从而计算因子的边缘概率，得到

$$
p(y_a)=\kappa \Psi_a( y_a)\prod_{s\in N(a)}m_{sa}(y_s) (4.30)
$$

其中，$$\kappa$$是归一化常量。实际上，这一想法适用于所有相连接的变量集——无须属于同一个因子——虽然当这一集合很大时，计算$$\kappa$$仍是不实际的。

BP也可用来计算归一化常数$$Z$$。可被传播算法直接计算得到，就像4.1节的前向后向算法。除此之外，也可在算法的末尾求得近似的边缘概率时去计算$$Z$$。对于树形结构的分布p( y)，可以发现联合分布总是按照下面的方式分解的：

$$
p(y)=\prod_{s\in V}p(y_s)\prod_a \frac{p( y_a)}{\prod_{t\in a}p(y_t)} (4.31)
$$

例如，对于线性链，这变成

$$
p(y)=\prod^T_{t=1}p(y_t)\prod^T_{t=1}\frac{p(y_t,y_{t-1})}{p(y_t)p(y_{t-1})} (4.32)
$$

通过消元、移项等操作，上式不过是我们熟悉的$$p(y)=\prod_t p(y_t,y_{t-1})$$的另一种写法而已。利用这一点，我们可以利用每个变量和因子的边缘概率计算p(y)。也可得到$$Z=p( y)^{-1}\prod_{a\in F}\Psi_a(y_a)$$。

如果G是一棵树，置信传播算法精确地计算得到边缘分布。实际上，如果G是线性链，BP退化成前向后向算法(4.1节)。为了说明这一点，请参考图4.2。该图展示了带3个节点的线性链，附带有我们刚描述的BP消息。为了与前向后向对应起来，我们在第4.1节记做$$alpha_2$$的前向信息对应于消息$$m_{A2}$$于$$m_{C2}$$的乘积(图中深灰色箭头)。反向消息$$\beta_2$$与消息$$m_{B2}$$相对应(图中浅灰色箭头)。实际上，式(4.30)对$$p( y_a)$$的解构是线性链(4.14)式的一般化。

![](/assets/4.2.png)

图4.2 前向后向算法与置信传播算法在线性链图中的一致性。具体请参考正文

如果G不是一棵树，(4.29)式对消息的更新不一定返回精确的边缘概率，也不能保证收敛性，但我们仍可迭代更新以求某个稳定点。这一过程叫做**循环置信传播loopy belief propagation**。为了强调这是求近似的过程，我们把循环BP得到的边缘概率称为置信 (beliefs)，而不是边缘概率，并记做$$q(y_s)$$。

现在，仍需要确定更新消息的顺序。在树形结构中，任何传播顺序都会收敛于正确的边缘分布，对循环传播却不行。甚至，消息更新的顺序不仅会影响最终的结果，还会影响算法是否收敛。实践中表现良好的一个简单选择是随机地更新消息。例如，随机地将因子排序，然后对每个因子依次按照(4.29)发送再接收消息。然而，更复杂的策略【35,135,152】也可以是有效的。

奇怪的是，循环BP也可被看成推算的变分法。就是说，存在置信的目标函数可被BP过程近似地最小化。我们在下文给出这一论点的综述，而更多的细节请供参考文章【150,158】。

一个变分算法背后的一般思想是：

(1)定义一组可控的近似$$\mathcal{Q}$$，以及对于$$q\in\mathcal{Q}$$定义一个目标函数$$\mathcal{O}(q)$$。每个$$q$$可以是边缘概率易于计算的分布，也可以直接是一组边缘分布的近似。如果是后者，那么近似的边缘概率常被称为**伪边缘概率 pseudomarginals**，因为它们不必是$$ y$$的联合分布的任何边缘概率。函数$$\mathcal{O}$$必须设计成是 对$$q\in \mathcal{Q}$$与$$p$$的近似程度的测量。

(2)找到“最近”的近似$$q^*=\min_{q\in\mathcal{Q}}\mathcal{O}(q)$$。

(3)用$$q^*$$来近似p的边缘概率。

例如，我们取$$\mathcal{Q}$$为y的所有可能的分布的集合，并取目标函数为：

$$
\mathcal{O}(q)=KL(q||p)-\log Z (4.33)
$$

$$
=-H(q)-\sum_a\sum_{ y_a}q( y_a)\log \Psi_a( y_a), (4.34)
$$

一旦通过优化获得了$$q^*$$，我们可以用$$q^*$$的边缘概率来近似q的。实际上，这个问题的解是$$q^*=p$$且$$\mathcal{O}(q^*)=-\log Z$$。因此，解这个变分问题就相当于精确地推断。可以通过改变集合$$\mathcal{Q}$$来设计推断方法——例如让$$q$$ 充分地分解(fully factorized)或使用别的目标函数$$\mathcal{O}$$。例如，平均场方法(mean field method)是通过要求q充分地分解而提出的，即选择某些$$q_s$$满足$$q( y)=\prod_sq_s(y_s)$$，并找到使式(4.34)的$$\mathcal{O}(q)$$最大化的q。

有了上面的变分法的背景知识，让我们看看如何将置信传播算法放入这个框架。我们做两个近似。首先，我们近似了式(4.34)的难以计算的熵H(q)。如果q是一棵树，那么气上可精确地写为

$$
H_{_{BETHE}}(q)=-\sum_a\sum_yq(y_a)log q(y_a)+\sum_i\sum_{y_i}(d_i-1)q(y_i)log q(y_i) (4.35)
$$

其中$$d_i$$是i的阶，表示连接到$$y_i$$上的因子的数量。这是通过把联合分布的树形因子分解式(4.31)带入熵的定义得到的。如果q不是一棵树，我们仍然可以把$$H_{_{BETHE}}$$看成H的近似，用于计算精确的变分目标函数$$\mathcal{O}$$。这带来了Bethe free熵：

$$
\mathcal{O}(q)=-H_{_{BETHE}}(q)-\sum_a\sum_{y_a}q(y_a)\log\Psi_a(y_a) (4.36)
$$

目标函数$$\mathcal{O}_{_{BETHE}}$$只通过它的边缘概率依赖于$$q$$，因而与其在所有可能的分布$$q$$上寻优，不如在所有的边缘概率向量所构成的空间里寻优。特别低，每个分布$$q$$有一个配套的置信向量(belief vector)$$ q$$，其元素为$$q_{a;y_a}$$(对应一个因子$$a$$以及相关变量$$y_a$$的取值)和$$q_{i;y_i}$$(对应每个变量$$i$$及其取值)。所有可能的置信向量组成的空间，又被称为marginal polytope【150】。然而对于棘手的模型，其marginal polytope的结构可能及其复杂。

这给我们带来了第二种变分近似——循环BP。其中，目标函数$$\mathcal{O}$$是在松弛的marginal polytope 上最小化的。松弛是因为它只要求置信(beliefs)在局部一致(locally consitent)，就是说，

$$
\sum_{y_a\backslash y_i}q_a( y_a)=q_i(y_i)\forall a,i\in a  (4.27)
$$

从技术的角度讲，如果一组推定的边缘分布满足(4.27)式，并不意味着他们在整体上一致(globally consistent)。即是说，存在一个唯一的联合概率q(y)拥有这些边缘概率(that there exists a single joint q(y) that has those marginals<font color=red>我没能理解这句话</font>)。因此，分布$$q_a(y_a)$$又被称为**伪边缘概率(pseudomarginal)**。

Yedidia 等【157】证明了，在约束(4.37)下，$$\mathcal{O}$$的驻点是循环BP的固定点。所以，我们可以把$$\mathcal{O}$$看成是，循环BP固定点运算所尝试优化的，目标函数。

这一变分视角让我们对该方法有了新的深入理见解，而这是不能单单从信息传递视角所想到的。一个最重要的见解是关于如何用循环BP来近似$$\log Z$$的。因为我们用$$\min_q\mathcal{O}_{_{BETHE}}(q)$$来近似$$\min_q \mathcal{O}(q)$$，而$$\min_q\mathcal{O}(q)=\log Z$$，因而用$$\log Z_{BETHE}=\min_q \mathcal{O}_{BETHE}(q)$$来近似$$\log Z$$是合理的。当我们在5.4.2节讨论CRF的参数估计时，这一点就很重要了。

## 4.3 实现方面的注意点

这一节，我们讲述一些在CRFs推断的实践中尤其重要的技术：稀疏性以及防止数值溢出。

首先，利用模型的稀疏性常常能够加快推断。有两类相关的稀疏性：因子值的稀疏性和特征的稀疏性。首先是关于因子值，记得在线性链时，每次前向更新(4.6)和后向更新(4.9)要被执行$$O(M^2)$$次。就是说，与标签的数量M的二次方有关。相似地在通用CRFs中，如果因子是连接着成对的两个变量，那么一次循环BP的更新也需要$$O(M^2)$$次。然而在某些模型中可更高效地实现推断，因为存在先验知识，知道不是所有的因子的取值$$y_t,y_{t-1}$$都是可能的。就是说，对于许多的取值$$y_t,y_{t-1}$$，因子$$\Psi_t(y_t,y_{t-1}$$总是0。这时，把消息传递迭代变成稀疏矩阵运算可以节省计算量。

另一种有用的稀疏性是特征向量的稀疏性。回忆一下(2.26)，计算一个因子$$\Psi_c( x_c, y_c)$$需要计算 参数向量$$\theta_p$$和特征向量$$ f_c\{f_{pk}(y_c, x_c)|\forall p,\forall k\}$$的内积。一般来说，向量$$ f_c$$的许多元素是0。例如自然语言处理常常包含单词是否出现作为特征。这时，使用稀疏向量方式可以节省大量的计算因子$$\Psi_c$$的时间。类似地，我们可以用稀疏性来减少似然梯度的计算时间，如第5节所讨论的。

还有一个可以加快前向后向算法的技巧，就是将某些参数与某些转移(trainsitions)绑定起来【24】。这减少了模型的转移矩阵的大小，减轻计算量与标签数量的二次方关系。

第二个实现推断时需注意的是如何避免数值溢出。前向后向算法和置信传播的概率值，如$$\alpha_t$$和$$m_{sa}$$，通常比数值的精度还小<font color="red">小于浮点数的数值精度</font>(例如HMM中的$$\alpha_t$$，随着$$t$$以指数的方式趋向于0)。有两个标准的方法来解决这一常见问题。一种方式是将每个$$\alpha_t$$和$$\beta_t$$归一化，从而剔除小的值。这一缩放不会影响对Z(x)的计算，因为可以按照$$Z(x)=p(y'| x)^{-1}\prod_t(\Psi_t(y'_t,y'_{t+1}, x_t))$$来计算，其中$$p(y'| x)^{-1}$$是从(4.31)的边缘概率计算来的。然而实际上，【111】描述了更有效的方法，其中的缩放技巧可用于前向后向算法以及循环BP。不管怎么样，它不影响最后的置信值(values of the beliefs)。

防止数值溢出的第二个方法是在对数域完成计算。即是说，前向递归(4.6)变成：

$$
\log \alpha_t(j)=\bigoplus_{i\in S}\left(\log \Psi_t(j,i,x_t)+\log \alpha_{t-1}(i)\right) (4.38)
$$

其中，$$\bigoplus$$表示$$a\bigoplus b=\log(e^a+e^b)$$。一开始，这似乎不能改进什么，因为数值精度在计算$$e^a$$和$$e^b$$时有所损失。然而，$$\bigoplus$$可以计算成：

$$
a\bigoplus b=a+\log(1+e^{b-a})=b+\log(1+e^{a-b}) (4,39)
$$

当我们选择小一点的指数时，这一运算的数值稳定性要好很多。

初一看，我们喜欢归一化方法胜过对数域方法，因为对数域方法需要$$O(TM^2)$$次调用耗时的$$\log$$和$$\exp$$运算。这对HMMs是对的，但不是CRFs。因为CRFs总归是要调用$$\exp$$来计算$$\Psi_t(y_t,y_{t+1}, x_t)$$，哪怕在归一化方法中。因此在CRFs中，调用这些运算不可避免。在最坏的时候，有$$TM^2$$个这样的$$\Psi_t$$，因而归一化方法需要调用这些特殊的函数$$TM^2$$次，与指数域方法一样。然而，有一些特殊的情况，归一化方法可以更快，如当转移特征不依赖于观测时，那么只有$$M^2$$个不同的$$\Psi_t$$。

















