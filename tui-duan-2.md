# 4.2 图模型的推断

通用图模型的精确推断算法也有不少。最槽糕的时候，它们需要指数级别的耗时，但在工程实践中扔不失为有效的方法。最流行的精确算法是联和树算法。它连续地把变量组合起来，使整个图变成一棵树。一旦这棵等效树被建立了起来，我们就可以用已有的、针对树的精确推断算法了。然而对于某些复杂的图，联合树算法需要做规模巨大的聚类，使它在最槽糕时仍需要指数级别的计算时间。关于精确算法的更多细节，请参考Koller和Friedman【57】。

由于精确推断的复杂性，大量的努力朝向了近似推断算法。有两类近似算法获得了最多的关注：蒙特卡洛算法和变分法。蒙特卡洛算法是统计算法，尝试从分布中近似地产生样本。变分法把推断问题转变成最优化问题，然后尝试找到边缘概率的最近的估计。一般来说，只要给与足够的时间，蒙特卡洛算法总能无偏地从分布中进行采样，但在实践中一般无法知道何时做到了这一点。变分法非常快速，但倾向于偏差，就是说，它天生具有一些误差，且哪怕拥有足够的计算时间也不能消除。尽管如此，变分法对CRFs是有用的。因为参数估计需要多次执行推断，所以快速的推断对于高效地训练十分关键。关于蒙特卡洛算法，可参考Robert和Casella【116】。对于变分方法，可参考Wainwright和Jordan【150】。

从两个方面，本节的内容特别针对CRFs，但也适用于从某些因子图得来的任何分布，不管它是联合分布p(y)，还是像CRFs的条件分布p(y|x)。为了强调这一点，也为了简化记号，我们去掉了对x的依赖，而只讨论联合分布p(y)的推断。该分布从某些因子图G=(V,F)而来，即

$$
p(y)=Z^{-1}\prod_{a\in F}\Psi_a(y_a).
$$

若想将这里的讨论用于CRFs，只需用$$\Psi_a(y_a,x_a)$$替换上面的$$\Psi_a(y_a)$$，同时将Z换成p(y)。这样就可以对x依赖了。这不仅是记号的问题，还会影响到具体的实践：推断算法可实现成适用于一般的因子图，而无需知道它是无向的联合分布p(y)，还是CRF的p(y|x)，或甚至是有向的图模型。

在本节的剩余部分，我们扼要地介绍近似推断算法的两个例子，分别来自两个大类。我们不能在这里包含所有的 近似推断算法。相反地，我们的目标是想强调近似推断算法给CRF的训练带来的一般性问题。本节中，我们关注推断算法本身，而在第5节介绍它们在CRFs中的应用。

## 4.2.1马尔科夫链蒙特卡洛

当前最流行的复杂模型的蒙特卡洛方法是马尔科夫链蒙特卡洛 (MCMC)【116】。它不去直接估计边缘概率$$p(y_s)$$，而是从联合分布p(y)中产生估计样本。MCMC方法通过构造一个马尔科夫链，使其状态空间与Y相同，小心地用该链做仿真足够长的时间，使得链的状态分布接近$$p(y_s)$$。假如函数f(y)服从分布p(y)，而我们想估计它的期望。给定MCMC方法的马尔科夫链的一组样本$$y^1,y^2,\cdots,y^M$$，我们可以通过下式来估计这个期望

$$
\sum_{y}p(y)f(y)\approx \frac{1}{M}\sum^M_{j=1}f(y^j) (4.21)
$$

下一节我们将发现，CRF的训练需要这一形式的期望。
MCMC方法的一个简单例子是Gibbs采样。在Gibbs算法的每个迭代周期里，每个变量独立地被重采样而保持其他变量不变。假如我们已经在第j次采样获得了样本$$y^j$$，那么需要产生下一个样本$$y^{j+1}$$
(1)取$$y^{j+1}= y^j$$。
(2)对每个$$s\in S$$，重采样$$Y_s$$。从分布$$p(y_s|{y}_{\backslash s}, x)$$中采样$$y^{j+1}_s$$。
(3)返回$$y^{j+1}$$作为结果。

回忆一下地2.1.1节，$$\sum_{y\backslash y_s}$$表示求和运算要遍历$$ y$$的所有可能取值，除了$$Y_s$$取值$$y_s$$。

上面的过程定义了一个马尔科夫链，可用于近似式(4.21)的期望。对于通用因子图，条件概率可按照下式计算

$$
p(y_s|y_{\backslash s})=\kappa \prod_{a\in F} \Psi_a(y_a),(4.22)
$$

其中，$$\kappa$$是归一化常量。(下文中，$$\kappa$$是一般意义的归一化常量，不要求在不同的式子中取相同的值)。式(4.22)的$$\kappa$$要比联合概率p(y|x)容易计算得多，因为它只需遍历$$y_s$$的所有可能取值，而不是整个y向量。

Gibbs的一个主要优点是它易于实现。实际上，像BUGS这种软件包允许以图模型作为输入，自动编译一个Gibbs取样器用于近似【78】。Gibbs的主要缺点是，当p( y)存在强相关时，Gibbs性能较差，而这在序列形式的数据中很常见。关于性能较差，我们的意思是，它需要很多次迭代才能让马尔科夫链的样本接近于所需的分布p(y)。

有大量的关于MCMC算法的文献。Robert和Casella的教材【116】提供了一个综述。然而，CRFs领域却不常用MCMC算法。原因可能正如我们说过的，极大似然方法做参数估计时，需要计算边缘概率很多次。不考虑复杂的策略，那么每次梯度下降时，都要为每一个参数集的每一个训练样本运行一次MCMC链。而MCMC链自身就需要千把次迭代才能收敛，使得这种方法在计算上难以实行。读者可能想到了一些解决办法，比如不等马尔科夫链收敛就返回(参考地5.4.3节)。

## 4.2.2 置信传播

**置信传播belief propagation(BP)**是一种重要的变分推断算法<font color=red>variational inference algorithm 翻译成变分推断算法似乎不合适。这里似乎只是"变体"的含义，把推断问题变成优化问题。</font>我们将在本节解释它。BP同时还是线性链CRFs的精确推断算法的一般化。

假如因子图G=(V,F)是一棵树，而我们希望计算变量$$Y_s$$的边缘概率。BP背后的思想在于，它认为每个与$$Y_s$$相连的因子按照乘法来提供边缘概率，我们称它们为**信息message**。因为图是一棵树，所以每个信息可被单独计算。更正式地，对每个因子$$a\in N(s)$$，记$$G_a=(V_a,F_a)$$为包含$$Y_s\Psi_a$$以其$$\Psi_a$$全部"上游"的G的子图。所谓的"上游"，我们指$$V_a$$包含了所有被$$\Psi_a$$隔开，从而与$$Y_s$$分离的变量，以及从而与$$F_a$$分离的因子。参见图4.1。对于每个$$a\in N(s)$$，每个$$V_a\backslash Y_s$$相互独立，因为G是一棵树。对$$F_a$$亦如此。这意味着，我们可以把边缘概率所需的求和运算划分成多个独立的子问题相乘，即

$$
p(y_s)\propto \sum_{ y\backslash {y_s}}\prod_{a\in F}\Psi_a(y_a) (4.21)
$$

$$
=\sum_{ y\backslash {y_s}}\prod_{a\in N(s)}\prod_{\Psi_b\in F_a}\Psi_b({y}_b) (4.24)
$$

$$
=\prod_{a\in N(s)}\sum_{ y_{V_a}\backslash {y_s}}\prod_{\Psi_b\in F_a}\Psi_b({y}_b) (4.25)
$$

虽然上面的记号不够明显，但需注意变量$$y_s$$包含在每个$$y_a$$中，所以它在(4.25)的两边都出现了。

![](/assets/4.1.png)

<center>图4.1 树形图的边缘分布是如何被划分的。这一划分被置信传播算法(4.2.2)所用。</center>

把上式的每个因子记为$$m_{as}$$，那么

$$
m_{as}(y_s)=\sum_{y_{V_a}\backslash y_s}\prod_{\Psi_b\in F_a}\Psi_b(y_b) (4.26)
$$

每个$$m_{as}$$正是从子图$$G_a$$过来的关于变量的$$y_s$$的边缘分布。$$y_s$$在全图上的边缘分布，正是每个子图上的边缘分布的乘积。这就好比$$m_{as}(y_s)$$是因子a传给$$Y_s$$的**信息message**，而这一信息汇合a上游的全部作用。同样地，我们可定义从变量到因子的信息:

$$
m_{sa}(y_s)=\sum_{ y_{V_a}}\prod_{\Psi_b\in F_s}\Psi_b(y_b) (4.27)
$$

然后考虑(4.25)式，我们知道边缘概率$$p(y_s)$$与所有到达$$Y_s$$的消息的乘积成比例。同样地，因子的边缘概率可计算为：

$$
p( y_a)\propto \Psi_a(y_a)\prod_{s\in N(a)}m_{sa}(y_a) (4.28)
$$

直接按照(4.26)式计算消息还不行，因为需要遍历$$y_{V_a}$$的所有可能取值来进行求和运算，而有时$$V_a$$是很大的集合。幸运的是，消息也可被写成递归的形式，从而只需局部的求和。递归形式是：

$$
m_{as}(y_s)=\sum_{ y_a\backslash y_s}\Psi_a( y_a)\prod_{t\in a\backslash s}m_{ta}(y_t)
$$

$$
m_{sa}(y_s)=\prod_{b\in N(s)\backslash a}m_{bs}(y_s). (4.29)
$$

通过依次带入，可知这一递归形式符合$$m$$的定义，也可通过数学归纳法证明。对于树形图，有可能通过合理的安排，使得每个消息被发送之前已收到它所依赖的上游消息，比如首先从根开始发送消息。这就是置信传播算法【103】。

除了计算单个变量的边缘概率，我们也希望计算银子的概率$$p(y_a)$$和联合概率p(y)。(回忆一下，后面这个任务是困难的，因为要计算归一化函数$$\log Z$$)。首先，我们可以像单个变量那样解构，从而计算因子的边缘概率，得到

$$
p(y_a)=\kappa \Psi_a( y_a)\prod_{s\in N(a)}m_{sa}(y_s) (4.30)
$$

其中，$$\kappa$$是归一化常量。实际上，这一想法适用于所有相连接的变量集——无须属于同一个因子——虽然当这一集合很大时，计算$$\kappa$$仍是不实际的。

BP也可用来计算归一化常数Z。可被传播算法直接计算得到，就像4.1节的前向后向算法。除此之外，也可在算法的末尾求得近似的边缘概率时去计算Z。对于树形结构的分布p( y)，可以发现联合分布总是按照下面的方式分解的：

$$
p(y)=\prod_{s\in V}p(y_s)\prod_a \frac{p( y_a)}{\prod_{t\in a}p(y_t)} (4.31)
$$

例如，对于线性链，这变成

$$
p(y)=\prod^T_{t=1}p(y_t)\prod^T_{t=1}\frac{p(y_t,y_{t-1})}{p(y_t)p(y_{t-1})} (4.32)
$$

通过消元、移项等操作，上式不过是我们熟悉的$$p(y)=\prod_t p(y_t,y_{t-1})$$的另一种写法而已。利用这一点，我们可以利用每个变量和因子的边缘概率计算p(y)。也可得到$$Z=p( y)^{-1}\prod_{a\in F}\Psi_a(y_a)$$。

如果G是一棵树，置信传播算法精确地计算得到边缘分布。实际上，如果G是线性链，BP退化成前向后向算法(4.1节)。为了说明这一点，请参考图4.2。该图展示了带3个节点的线性链，附带有我们刚描述的BP消息。为了与前向后向对应起来，我们在第4.1节记做$$alpha_2$$的前向信息对应于消息$$m_{A2}$$于$$m_{C2}$$的乘积(图中深灰色箭头)。反向消息$$\beta_2$$与消息$$m_{B2}$$相对应(图中浅灰色箭头)。实际上，式(4.30)对$$p( y_a)$$的解构是线性链(4.14)式的一般化。

![](/assets/4.2.png)

图4.2 前向后向算法与置信传播算法在线性链图中的一致性。具体请参考正文

如果G不是一棵树，(4.29)式对消息的更新不一定返回精确的边缘概率，也不能保证收敛性，但我们仍可迭代更新以求某个稳定点。这一过程叫做**循环置信传播loopy belief propagation**。为了强调这是求近似的过程，我们把循环BP得到的边缘概率称为置信 (beliefs)，而不是边缘概率，并记做$$q(y_s)$$。

现在，仍需要确定更新消息的顺序。在树形结构中，任何传播顺序都会收敛于正确的边缘分布，对循环传播却不行。甚至，消息更新的顺序不仅会影响最终的结果，还会影响算法是否收敛。实践中表现良好的一个简单选择是随机地更新消息。例如，随机地将因子排序，然后对每个因子依次按照(4.29)发送再接收消息。然而，更复杂的策略【35,135,152】也可以是有效的。

奇怪的是，循环BP也可被看成推算的变分法。就是说，存在置信的目标函数可被BP过程近似地最小化。我们在下文给出这一论点的综述，而更多的细节请供参考文章【150,158】。

一个变分算法背后的一般思想是：

(1)定义一组可控的近似$$\mathcal{Q}$$，以及对于$$q\in\mathcal{Q}$$定义一个目标函数$$\mathcal{O}(q)$$。每个$$q$$可以是边缘概率易于计算的分布，也可以直接是一组边缘分布的近似。如果是后者，那么近似的边缘概率常被称为**伪边缘概率 pseudomarginals**，因为它们不必是$$ y$$的联合分布的任何边缘概率。函数$$\mathcal{O}$$必须设计成是 对$$q\in \mathcal{Q}$$与$$p$$的近似程度的测量。

(2)找到"最近"的近似$$q^*=\min_{q\in\mathcal{Q}}\mathcal{O}(q)$$。

(3)用$$q^*$$来近似p的边缘概率。

例如，我们取$$\mathcal{Q}$$为y的所有可能的分布的集合，并取目标函数为：

$$
\mathcal{O}(q)=KL(q||p)-\log Z (4.33)
$$

$$
=-H(q)-\sum_a\sum_{y_a}q(y_a)\log \Psi_a( y_a) (4.34)
$$

一旦通过优化获得了$$q^*$$，我们可以用$$q^*$$的边缘概率来近似q的。实际上，这个问题的解是$$q^*=p$$且$$\mathcal{O}(q^*)=-\log Z$$。因此，解这个变分问题就相当于精确地推断。可以通过改变集合$$\mathcal{Q}$$来设计推断方法——例如让$$q$$ 充分地分解(fully factorized)或使用别的目标函数$$\mathcal{O}$$。例如，平均场方法(mean field method)是通过要求q充分地分解而提出的，即选择某些$$q_s$$满足$$q( y)=\prod_sq_s(y_s)$$，并找到使式(4.34)的$$\mathcal{O}(q)$$最大化的q。

有了上面的变分法的背景知识，让我们看看如何将置信传播算法放入这个框架。我们做两个近似。首先，我们近似了式(4.34)的难以计算的熵H(q)。如果q是一棵树，那么气上可精确地写为

$$
H_{_{BETHE}}(q)=-\sum_a\sum_yq(y_a)log q(y_a)+\sum_i\sum_{y_i}(d_i-1)q(y_i)log q(y_i) (4.35)
$$

其中$$d_i$$是i的阶，表示连接到$$y_i$$上的因子的数量。这是通过把联合分布的树形因子分解式(4.31)带入熵的定义得到的。如果q不是一棵树，我们仍然可以把$$H_{_{BETHE}}$$看成H的近似，用于计算精确的变分目标函数$$\mathcal{O}$$。这带来了Bethe free熵：

$$
\mathcal{O}(q)=-H_{_{BETHE}}(q)-\sum_a\sum_{y_a}q(y_a)\log\Psi_a(y_a) (4.36)
$$

目标函数$$\mathcal{O}_{_{BETHE}}$$只通过它的边缘概率依赖于$$q$$，因而与其在所有可能的分布$$q$$上寻优，不如在所有的边缘概率向量所构成的空间里寻优。特别低，每个分布$$q$$有一个配套的置信向量(belief vector)$$ q$$，其元素为$$q_{a;y_a}$$(对应一个因子$$a$$以及相关变量$$y_a$$的取值)和$$q_{i;y_i}$$(对应每个变量$$i$$及其取值)。所有可能的置信向量组成的空间，又被称为marginal polytope【150】。然而对于棘手的模型，其marginal polytope的结构可能及其复杂。

这给我们带来了第二种变分近似——循环BP。其中，目标函数$$\mathcal{O}$$是在松弛的marginal polytope 上最小化的。松弛是因为它只要求置信(beliefs)在局部一致(locally consitent)，就是说，

$$
\sum_{y_a\backslash y_i}q_a( y_a)=q_i(y_i)\forall a,i\in a  (4.27)
$$

从技术的角度讲，如果一组推定的边缘分布满足(4.27)式，并不意味着他们在整体上一致(globally consistent)。即是说，存在一个唯一的联合概率q(y)拥有这些边缘概率(that there exists a single joint q(y) that has those marginals<font color=red>我没能理解这句话</font>)。因此，分布$$q_a(y_a)$$又被称为**伪边缘概率(pseudomarginal)**。

Yedidia 等【157】证明了，在约束(4.37)下，$$\mathcal{O}$$的驻点是循环BP的固定点。所以，我们可以把$$\mathcal{O}$$看成是，循环BP固定点运算所尝试优化的，目标函数。

这一变分视角让我们对该方法有了新的深入理见解，而这是不能单单从信息传递视角所想到的。一个最重要的见解是关于如何用循环BP来近似$$\log Z$$的。因为我们用$$\min_q\mathcal{O}_{_{BETHE}}(q)$$来近似$$\min_q \mathcal{O}(q)$$，而$$\min_q\mathcal{O}(q)=\log Z$$，因而用$$\log Z_{BETHE}=\min_q \mathcal{O}_{BETHE}(q)$$来近似$$\log Z$$是合理的。当我们在5.4.2节讨论CRF的参数估计时，这一点就很重要了。