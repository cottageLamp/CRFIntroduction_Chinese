# 5.参数估计

这一节，我们讲述如何估计CRF的参数$$\theta=\{\theta_k\}$$。在最典型、最简单的情况下，数据是完全标注的，但也有研究是关于半监督CRF、带隐藏变量的CRF和关系学习的CRF。

极大似然是一种训练CRF的方法，就是说，要选择参数，使训练数据在模型意义下具有最高的概率。原理上，它与逻辑回归的做法很像。考虑我们在第2节所讲述的这些模型之间的联系，这一点应该不让人意外。主要的区别点在于计算方面：CRF倾向拥有更多参数、更复杂的结构，导致了更高的训练成本。

在树形CRF中，极大似然可基于数值优化过程，以第4.1节江苏的推断算法为子过程。推断算法同时计算了似然和它的梯度。一般来说，似然是关于参数的凸函数，意味着有效的优化过程是现成的，且一定收敛到最优点。

我们从讲述极大似然开始，包含有线性链（第5.1.1节）和通用图结构（第5.1.2节），还包括隐藏变量的情况。我们也将讲述两种加快参数训练的方法：随机梯度下降法（挖掘数据中的 iid 结构，第5.2节）和多线程训练（第5.3节）。

对于通用CRF，精确的极大似然训练是不存在的，因而需要近似过程。泛泛地说，有两种解决问题的策略。一是使用易于计算的函数来近似该似然，叫做**代理似然surrogate likelihood**，再数值地优化该代理函数。第二种方法是边缘概率近似。它在极大似然训练需要精确计算的时候，嵌入一个近似的推断算法来计算边缘分布。这里需要小心，因为近似推断和学习之间存在着微妙而复杂的作用。我们在第5.4节讨论这些。

## 5.1极大似然

### 5.1.1线性链CRF

线性链CRF的极大似然参数可以用数值优化的方法确定。我们拥有iid训练数据$$\mathcal{D}=\{\pmb x^{(i)},\pmb y^{(i)}\}^N_{i=1}$$，其中$$\pmb x^{(i)}=\{x^{(i)}_1,x^{(i)}_2,\cdots,x^{(i)}_T\}$$是一系列输入，而$$\pmb y^{(i)}=\{y^{(i)}_1,y^{(i)}_2,\cdots,y^{(i)}_t\}$$是期望的预测结果。为了简化符号，我们假设每个训练序列$$\pmb x^{(i)}$$的长度都是$$T$$。一般来说，每个序列的长度不必相同——也就是说，$$T$$依赖于$$i$$。下面的讨论可直接扩展以覆盖这种情况。

参数估计一般通过带惩罚项的极大似然来完成。因为我们对条件分布建模了，那么如下的$$\log$$似然，有时也叫**条件$$\log$$似然**，正合适：
$$
\ell(\theta)=\sum^N_{i=1}\log p(\pmb y^{(i)}|\pmb x^{(i)};\theta). (5.1)
$$
计算极大似然估计，实际是最大化$$\ell(\theta)$$。就是说，所求的估计为$$\hat{\theta}_{ML}=\sup_{\theta}\ell(\theta)$$。

一种理解$$p(\pmb y^{(i)}|\pmb x^{(i)};\theta)$$的办法，是想象它与某各任意的先验概率$$p(\pmb x;\theta)$$结合以构成联合分布概率$$p(\pmb{y,x})$$。然后我们的联合$$\log$$似然为
$$
\log p(\pmb y|\pmb x;\theta)=\log p(\pmb{y|x};\theta)+\log p(\pmb x;\theta'), (5.2)
$$
注意，项$$p(\pmb x;\theta')$$与条件分布的 参数$$\theta$$无关。如果我们不用估计$$p(\pmb x)$$，那么当计算$$\theta$$的极大似然估计时，那么可以直接去掉（5.2）中的第二项。结果正是（5.1）。

将CRF的模型（2.18）带入（5.1），我们得到：
$$
\ell(\theta)=\sum^N_{i=1}\sum^T_{t=1}\sum^K_{k=1}\theta_kf_k(y^{(i)}_t,y^{(i)}_{t-1},\pmb x^{(i)}_t)-\sum^N_{i=1}\log Z(\pmb x^{(i)}),(5.3)
$$
通常，我们拥有数量庞大的参数，如几十万个。为了避免过拟合，我们使用**规则化regularization**，就是对权重向量过大的模进行惩罚。常见的惩罚项是$$\theta$$的欧几里得范数，以及**规则化参数$$1/2\sigma^2$$来定义惩罚强度。规则化的$$\log$$似然为
$$
\ell=\sum^N_{i=1}\sum^T_{t=1}\sum^K_{k=1}\theta_kf_k(y^{(i)}_t,y^{(i)}_{t-1},\pmb x^{(i)}_t)-\sum^N_{i=1}\log Z(\pmb x^{(i)})-\sum^K_{k=1}\frac{\theta^2_k}{2\sigma^2}.(5.4)
$$
$$\sigma^2$$是一个自由参数，用来决定对大权重的惩罚力度。其直观想法是避免少数特征就支配了预测结果。根据规则化的写法，规则化可以被理解成最大化了一个后验(MAP)估计，就像$$\theta$$被赋予了均值为0方差为$$\sigma^2I$$的高斯后验分布一样<font color="red">不是特别清楚这里的意思，但也无关紧要。我在实践中用的是等式约束。</font>。确定最佳的规则化参数需要 高计算量的 参数扫描。幸运的是，所得模型的精度并不敏感于$$\sigma^2$$（如，10倍以内不会带来大的影响）。最佳的$$\sigma^2$$与训练数据集的大小有关。对于地5.5节江苏的训练集来说，我们通常去$$\sigma^2=10$$。

也可以用$$L_1$$范数来作为规则化，而这相当于对参数做了double exponential prior假设【44】。这得到如下的带惩罚的似然
$$
\ell'(\theta)=\sum^N_{i=1}\sum^T_{t=1}\sum^K_{k=1}\theta_kf_k(y^{(i)}_t,y^{(i)}_{t-1},\pmb x^{(i)}_t)-\sum^N_{i=1}\log Z(\pmb x^{(i)})-\alpha\sum^K_{k=1}|\theta_k|.(5.5)
$$
其中，$$\alpha$$是需要调节的规则化参数，就像$$L_2$$范数的$$\sigma^2$$。这种规则化鼓励稀疏的参数，即大多数$$\theta_k$$为0。这对特征选择很有用，以及另外理论上的优势【97】。实践中，用$$L_1$$规则化训练的模型更稀疏，但精度方面与$$L_2$$规则化大致相当【57】。$$L_1$$范数的缺点是它在0处不可导，某种程度上让数值优化变得复杂【3,44,160】。

一般来说，$$\ell(\theta)$$的极大值没有封闭解，因而需要数值优化。（5.4）的偏微分是
$$
\frac{\partial \ell}{\partial \theta_k}=\sum^N_{i=1}\sum^T_{t=1}f_k(y^{(i)}_t,y^{(i)}_{t-1},\pmb x^{(i)}_t)-\sum^N_{i=1}\sum^T_{t=1}\sum_{y,y'}f_k(y,y',\pmb x^{(i)}_t)p(y,y'|\pmb x^{(i)}_t)-\frac{\theta_k}{\sigma^2}.(5.6)
$$
可以把第一项看成$$f_k$$在经验分布$$\tilde{p}$$下的期望。这一分布的定义是
$$
\tilde{p}(\pmb {y,x})=\frac{1}{N}\sum^N_{i=1}\pmb 1_{\{\pmb y=\pmb y^{(i)}\}}\pmb 1_{\{\pmb x=\pmb x^{(i)}\}}.(5.7)
$$
第二项来自于$$\log Z(\pmb x)$$的偏导数，相当于$$f_k$$在模型分布$$p(\pmb {y|x};\theta)\tilde{p}(\pmb x)$$下的期望。因此，当规则化极大似然的达到它的解时，梯度为0，意味着这两个期望相等。这一优点是指数家族中极大似然估计的标准结果。

要计算似然$$\ell({\theta)}$$和它的微分，需要我们在第4节介绍的推断技术。首先在似然的计算中，推断被用来计算归一化函数$$Z(\pmb x^{(i)})$$，是需要遍历所有可能的标签值的。其次是在微分的计算中，推断被用来计算边缘分布$$p(y,y'|\pmb x^{(i)}_t)$$。因为这两个量都依赖于$$\pmb x^{(i)}$$，所以为每个样本计算似然时都要运行一次推断。这是与生成模型（如第2.1.1节介绍的无向生成模型）的一个不同点。极大似然也可以用于无向生成模型的训练，但此时$$Z$$只与参数有关，而与输入无关。一次似然的计算就要进行$$N$$次推断，而这激发了随机梯度上升方法（5.2节）。

现在我们讨论如何优化$$\ell{(\theta)}$$。函数$$\ell{(\theta)}$$是凹的，这是由于形式如$$g(\pmb x)=\log \sum_i \exp x_i$$的函数的凸性。凸性对参数估计很有帮助，因为它意味着每个局部极值点就是全局最优点。另外，如果使用了一个严格凹的规则化，如$$L2$$规则化，那么目标函数也变得严格地凹，这暗示它拥有唯一的全局最优点。

或许沿着梯度（5.6）最速上升是优化$$\ell$$的最简单方法，但这在实践中需要太多次迭代了。牛顿方法的收敛要快得多，因为它利用了似然的曲率，但是需要计算Hessian——二阶微分矩阵。Hessian矩阵的大小是参数个数的平方。既然工程中的应用常常使用几万甚至几百万个参数，简单地保存整个Hessian矩阵是不切实际的。

相反，（5.4）的优化需要对二阶信息做近似。特别成功的方法是准牛顿方法，如BFGS【8】。它从目标函数的一阶微分中计算Hessian矩阵的近似。完整的对Hessian矩阵的$$K\times K$$近似仍然需要二次方的尺寸，所以需要有限内存版本的BFGS——来自Byrd等【17】。共轭梯度是另一个对二阶信息做近似的优化技术，并在CRF中获得了成功。关于有限内存BFGS和共轭梯度的优秀介绍，请参考Nocedal和Wright【100】。也可想成是一个黑箱优化程序that is a drop-in replacement for vanilla gradient ascent。当使用了这些二阶方法之后，基于梯度的优化方法比Lafferty等【63】所介绍的那种原始的iterative scaling方法快得多。这被一些作者【80,92,125,153】实践表明了。最后，置信域方法最近在多项逻辑回归上表现良好【74】，因而或许也对CRF表现良好。

这些优化算法——最速下降，牛顿法，准牛顿法，共轭梯度法和置信域法——是非线性函数的标准数值优化技术。我们把它们看成CRF规则化极大似然的现成方法。这些算法通常需要能够计算目标函数的值和梯度。在我们这里，目标函数值是（5.4）式，而一阶导数在（5.6）式中给出了。这也是我们在第4节，除了边缘概率，还讲述了如何计算归一化函数$$Z(\pmb x)$$的原因。

最后，我们讨论一下训练线性链模型的计算代价。正如我们将在第4.1节看到的<font color="red">?</font>，单个训练样本的似然和梯度可在$$O(TM^2)$$次计算内，通过前向后向算法获得。其中$$M$$是标签的个数而$$T$$是训练样本的长度。因为我们需要为每个训练样本运行一次前向后向算法，所以一次似然和梯度的计算量为$$O(TM^2N)$$。所以总的训练代价为$$O(TM^2NG)$$。其中$$G$$是优化过程计算梯度的次数<font color="red">应该是迭代次数</font>。可惜，$$G$$依赖于数据集且难以提前估计。对于线性链的batch L-BFGS，这个数一般（但不总）是100。对很多数据集来说，这一计算量是合理的。但如果变量的个数$$M$$十分巨大，或者训练样本的个数$$N$$十分庞大时，可能会让训练变得昂贵。根据标签的数量，训练CRF可能需要几分钟或是几天——可参考5.5节的例子。

### 5.1.2 通用CRF

通用CRF的参数估计在本质上与线性链一样，只是对模型期望的计算需要更通用的推断算法。首先，我们讨论观测完整的情况，其中训练数据和测试数据相互独立。这时，条件$$\log$$似然，使用2.4节的记法，就是
$$
\ell(\theta)=\sum_{C_p=\mathcal{C}}\sum_{\Psi_c\in C_p}\sum^{K(p)}_{k=1}\theta_{pk}f_{pk}(\pmb x_c,\pmb y_c)-\log Z(\pmb x). (5.8)
$$
本节的方程都不显式地遍历训练样本集，因为如果某个应用刚好拥有 idd 训练样本<font red="red"> idd 是啥？</font>，那么可以用图$$G$$中断开的多个子块表示。

$$\log$$似然关于团模板$$C_p$$的参数$$\theta_{pk}$$的偏导数为：
$$
\frac{\partial \ell}{\partial \theta_{pk}}=\sum_{\Psi_c \in C_p}f_{pk}(\pmb{x_c,y_c})-\sum_{\Psi_c\in C_p}\sum_{\pmb y'_c}f_{pk}(\pmb{x_c,y'_c})p(\pmb{y'_c|x}).(5.9)
$$
上面的函数$$\ell(\theta)$$与线性链的具有许多共同的特点。首先，0梯度条件可以解释为“要求充分统计$$F_{pk}(\pmb{x,y})=\sum_{\Psi_c}f_{pk}(\pmb{x_c,y_c})$$在经验分布和模型分布下具有相同的期望。其次，函数$$\ell(\theta)$$是凹的，因而可以使用像共轭梯度或L-BFGS这样的二阶最大化技术来解。最后，规则化的方法与线性链如出一辙。

到目前为止的所有讨论，都假设训练数据包含完整的输出变量的值。**潜变量Latent variables**是一些在训练和测试时都未知的变量。在Quatoni等的【109,110】中，拥有潜变量的CRF被称为**隐状态hidden-state**CRF(HCRFs)。关于其他早期的HCRFs，请参考【84,138】。训练带潜变量的CRF要更困难，因为需要计算潜变量的边缘概率来完成推断。

假如我们的CRF的输入为$$\pmb x$$，$$\pmb y$$为训练数据集中可观测的变量，而$$\pmb w$$为另外的潜变量。从而，CRF具有如下形式
$$
p(\pmb {y,w|x})=\frac{1}{Z(\pmb x)}\prod_{C_p\in \mathcal{C}}\prod_{\Psi_c\in C_p}\Psi_c(\pmb{x_c,w_c,y_c;\theta_p}).(5.10)
$$
一种在训练时用来最大化的目标函数是如下的边缘似然：
$$
\ell ({\theta})=\log p(\pmb{y|x})=\log \sum_{\pmb w}p(\pmb{y,w|x}).(5.11)
$$
第一个问题是如何计算边缘似然$$\ell(\theta)$$，因为如果有许多变量$$\pmb w$$，那么求和就不能被直接计算。关键是要意识到，我们只需要遍历训练集中出现过的$$\pmb y$$，而不是所有可能的$$\pmb y$$，来计算$$\log \sum_{\pmb w}p(\pmb{y,w|x})$$。于是，利用原始的CRF（5.10），并让变量$$Y$$都取它们在训练集中的值，得到$$\pmb w$$的分布：
$$
p(\pmb{w|y,x})=\frac{1}{Z(\pmb{y,x})}\prod_{C_p\in\mathcal{C}}\prod_{\Psi_c\in C_p}\Psi_c(\pmb{x_c,w_c,y_c;\theta_p}),(5.12)
$$
其中，归一化因子为
$$
Z(\pmb{y,x)}=\sum_{\pmb w}\prod_{C_p\in\mathcal{C}}\prod_{\Psi_c\in C_p}\Psi_c(\pmb{x_c,w_c,y_c;\theta_p}).(5.13)
$$
可以像$$Z(\pmb x)$$那样去计算这一新的归一化常量$$Z(\pmb{y,x})$$。实际上，$$Z(\pmb{y,x})$$更易于计算，因为它只需遍历$$\pmb w$$来求和，而$$Z(\pmb x)$$需要遍历$$\pmb w$$和$$\pmb y$$。从图的角度，这相当于说，在图$$G$$中固定了$$\pmb y$$的值后，可以让只剩下$$\pmb w$$的结构得到简化。

一旦计算了$$Z(\pmb{y,x})$$，边缘似然可以按照如下方式计算
$$
p(\pmb{y|x})=\frac{1}{Z(\pmb x)}\sum_{\pmb w}\prod_{C_p\in \mathcal{C}}\prod_{\Psi_c\in C_p}\Psi_c(\pmb{x_c,w_c,y_c;\theta_p})=\frac{Z(\pmb{y,x})}{Z(\pmb{x})}.(5.14)
$$
现在我们已经拥有了计算$$\ell$$的方法，那么来讨论如何关于$$\theta$$来最大化它。因为$$\ell$$一般不再是凸的(log - sum-exp是凸的，但两个log-sum-exp的差却不一定了），所以求它的最大值是困难的。所以，优化过程一般只能保证得到局部极大点。不管使用了什么优化技术，都要特别小心地初始化模型的初始值，以达到全局最大值。

我们讨论最大化$$\ell$$的两种方法：像Quattoni等【109】那样直接使用梯度；像McCallum等【84】那样使用EM。（另外，这里也很适合使用随机梯度下降，第5.2节）要直接最大化$$\ell$$，我们需要计算梯度。利用下面的事实是最简单的方法。对于任何的函数$$f(\theta)$$，我们有
$$
\frac{df}{d\theta}=f(\theta)\frac{d\log f}{d\theta},(5.15)
$$
这里，我们对$$\log f$$使用了链式法则，并对公式做了调整。将这一点应用到边缘似然$$\ell(\theta)=\log\sum_{\pmb w}p(\pmb{y,w|x})$$得到
$$
\begin{align}
\frac{\partial \ell}{\partial \theta_{pk}}=&\frac{1}{\sum_{\pmb w}p(\pmb{y,w|x})}\sum_{\pmb w}\frac{\partial}{\partial\theta_{pk}}[p(\pmb{y,w|x})] (5.16)\\
=&\sum_{\pmb w}p(\pmb{w|y,x})\frac{\partial}{\partial\theta_{pk}}[\log p(\pmb{y,w|x})].(5.17)
\end{align}
$$
这是完整CRF的梯度的期望，是关于$$\pmb w$$的。这个表达式可简化为
$$
\frac{\partial\ell}{\partial\theta_{pk}}=\sum_{\Psi_c\in C_p}\sum_{\pmb w'_c}p(\pmb w'_c|\pmb{y,x})f_k(\pmb {y_c,x_c,w'_c})-\sum_{\Psi_c\in C_p}\sum_{\pmb w'_c,\pmb y'_c}p(\pmb{w'_c,y'_c|x_c})f_k(\pmb{y'_c,x_c,w'_c}).(5.18)
$$
这一梯度要求计算两类边缘概率。第一项包含了边缘概率$$p(\pmb{w'_c|y,x})$$，正是（5.12）式的收缩CRF的边缘分布。第二项包含了一种不同的边缘概率$$p(\pmb{w'_c,y'_c|x_c})$$，正是完整CRF所需的边缘概率。只要我们计算了这一梯度，就可以用标准的（像共轭梯度算法）技术来最大化$$\ell$$。对于BFGS，我们的经验是，依赖记忆（memory based）对Hessian矩阵的近似变得有歧义，这是因为凸性被破坏了，就像潜变量CRF这里的情况。有一种实践中的小技巧，当上面的情况发生时，重置对Hessian矩阵的近似。

除此之外，也可以通过期望最大化（EM）来优化$$\ell$$。在EM算法的每次迭代里，当前的 参数向量$$\theta^{(j)}$$通过如下方式更新。首先在E步（E-step）中，按照$$q(\pmb w)=p(\pmb{w|y,x};\theta^{(j)})$$计算得到一个松弛函数。其次在M步（M-step）中，一个新的参数向量$$\theta^{(j+1)}$$计算为
$$
\theta^{(j+1)}=\arg\max_{\theta'}\sum_{\pmb w'}q(\pmb w')\log p(\pmb{y,w'|x};\theta').(5.19)
$$
直接最大化算法与EM算法是显著地相似的。通过吧$$q$$带入(5.19)并求导可看到这一点。所得的梯度与直接梯度（5.18）式几乎一样。所不同的是，EM中的分布$$p(\pmb{w|y,x})$$是从预先确定的参数获得的，而不是从最大化过程中提取。我们目前尚缺乏两者在潜变量CRF中的对比的经验。

## 5.2 随机梯度方法

到目前为止，我们讨论过的优化方法适用于整批处理（batch setting）。就是说，它们先扫描完整个训练集后，才能更新模型的参数。如果训练数据的idd样本数量极大，这看起来很浪费。<font color="red">我还有一个经验——会造成梯度极大</font>。我们猜测，训练数据中的大量不同样本会提供近似的关于模型参数的信息，因而有可能不用扫描所有的样本，而是只读取少量样本后，就更新模型的参数。

**随机梯度下降Stochastic gradient descent(SGD)**是一种简单的优化方法，用来利用这一洞见。基本的想法是，在每次迭代里，随机地选择一个训练样本，然后采用这一样本带来的梯度，并使用一个小的步长。在整批处理的方案里，梯度下降通常不是有话的好方法，因为局部的最速下降方向（就是负的梯度）可能指向与最值点完全不同的地方。所以随机梯度方法含有一个有趣的权衡：L-BFGS的单步的迭代方向比SGD的好很多，但SGD方向的计算要快得多。

为了简化符号，我们只给出线性链的SGD。然而，它可以很容易用于任意的图结构——只要训练数据是iid 的。单个训练样本$$(\pmb x^{(i)},\pmb y^{(i)})$$的似然的梯度为：
$$
\frac{\partial \ell_i}{\partial\theta_k}=\sum^T_{t=1}f_k(y^{(i)}_t,y^{(i)}_{t-1},\pmb x^{(i)}_t)-\sum^T_{t=1}\sum_{\pmb{y,y'}}f_k(y,y',\pmb x^{(i)}_t)p(y,y'|\pmb x^{(i)})-\frac{\theta_k}{N\sigma^2}.(5.20)
$$
这与完整的梯度（5.6）一样，只是有两点不同：遍历所有样本的求和被去掉了，以及在规则化项中多出来的因子$$1/N$$。这保证整批的梯度等于单样本梯度的和，即$$\bigtriangledown\ell=\sum^N_{i=1}\bigtriangledown\ell_i$$，其中我们用$$\bigtriangledown\ell_i$$来表示单个样本$$i$$的梯度。

在SGD的每次迭代里，我们随机地选择一个样本$$(\pmb x^{(i)},\pmb y^{(i)})$$。然后从原有的向量$$\theta^{(m-1)}$$中计算新的参数向量如下
$$
\theta^{(m)}=\theta^{(m-1)}+\alpha_m\bigtriangledown\ell_i(\theta^{(m-1)}),(5.21)
$$
其中，$$\alpha_m>0$$，是步长参数，用于控制参数们在多大程度上演着梯度方向更新。如果步长过大，参数会在每次迭代里，沿着所选的样本的方向摆动过远。如果$$\alpha_m$$太小，则训练过程会非常慢，甚至在极端的例子中，从数值角度看参数已经收敛了，但其实离最小点还很远呢。

我们希望$$\alpha_m$$随着$$m$$的增大而减小，以让优化算法收敛到某个唯一的答案。随机近似过程【54,115】提供了收敛性的经典结果，即至少要求$$\sum_m\alpha_m=\infty$$以及$$\sum_m\alpha^2_m< \infty$$。即是说，$$\alpha$$应该收敛到0，但是不能过快。采用类似$$\alpha_m\sim \frac{1}{m}$$或$$\alpha_m\sim\frac{1}{\sqrt{m}}$$的步长是最常用的方法，能满足上面的要求。然而，简单地采用$$\alpha_m=1/m$$常常不好，因为第一个步长太大了。实际上，常见的技巧是如下的安排：
$$
\alpha_m=\frac{1}{\sigma^2(m_0+m)},(5.22)
$$
其中，$$m_0$$是一个自由参数。对于这一参数，有一个推荐的方法。Leon Bottou【13】的软件包$$crfsgd$$一次采样一个小的训练数据子集，然后在这一子集上使用各种固定步长$$\alpha$$运行SGD。选择$$\alpha^*$$，使得该子集的数据在一次运算后的似然是最大的，然后通过让$$\alpha_0=\alpha^*$$来确定$$m_0$$。

随机梯度下降算法在神经网络文献中又被称为反向传播。过去的许多年中，发展了大量的调节这一算法的技巧【66】。最近，先进在线优化方法【27,43,126,149】重新引发了关注。它也在线地更新参数，但比简单SGD更复杂。Vishwanathan等【149】是第一个在CRF中使用随机梯度方法的应用。

随机梯度方法的主要缺点是它们需要 tuning，这不同于现成的求解器如共轭梯度和L-BFGS。随机梯度方法也不能用于训练数据不是idd 的relational settings，也不能用于小的数据集。对于合适的数据集，共轭梯度方法可以带来可观的加速。

##5.3并行

随机梯度下降通过只计算少量的样本来加速计算过程。另一种加快计算的方法是并行地计算不同样本的梯度。因为梯度（5.6）是在所有的样本上求和，可以轻易地把计算划分成多个线程，其中每个线程只计算训练样本的一个子集的梯度。如果CRF在多核机器上运行，那么多个线程将并行运行，极大地加快了梯度计算。这一特点为许多常见的机器学习算法所共有，如Chu等【22】指出的。

原理上，人们也可以吧梯度计算分布到多个机器上，而不是同一台机器的多个核。然而在网络中传递大量的参数可能会成为问题。一种潜在的解决发办法是异步地更新参数。这一想法的最近一个例子是把并行计算融入随机梯度方法的【64】。

## 5.4近似训练

我们所描述过的训练方法，包括随机和并行梯度方法，都假定易处理的图结构。就是说，我们可以有效地计算归一化函数$$Z(\pmb x)$$和边缘分布$$p(\pmb y_c|\pmb x)$$。这对线性链和树形结构CRF是有效的。早期的CRF关注于它们，即是因为它们的推断易于完成，也因为它们很自然地适合一些任务，如NLP中的序列标注任务。

当图的结构更复杂时，边缘分布和归一化函数都不是易于计算的，使我们必须凭借近似手段。如地4节所说的，存在着大量的近似推断算法。在讨论CRF时，却有一个需要进一步考虑的关键问题——近似推断被嵌入到更大的参数优化过程里。

有两个通用的近似训练CRF的策略【139】：**代理似然surrogate likelihood**策略（通过修改目标函数）和**近似边缘概率approximate marginals**策略（通过近似梯度）。第一种策略要寻找$$\ell(\theta)$$的替代者（就像BP近似（5.27）），被称作代理似然。它需是易于计算的同时，仍偏爱着好的参数。然后用基于梯度的方法来优化这一代理似然，就像真实似然一样。近似边缘策略使用通用的推断算法来计算边缘$$p(\pmb y_c|\pmb x)$$的近似，然后在式（5.9）中用近似概率替代精确概率，再用这一近似梯度来完成梯度下降过程。

虽然代理似然和近似边缘概率方法紧密相关，但却是不同的。通常一个代理似然方法直接产生一个近似概率方法，因为就像$$\log Z(\pmb x)$$的导数给出了真实的边缘概率，近似的$$\log Z(\pmb x)$$也可以看成是边缘概率的近似。这些近似的边缘概率有时被称为**pseudomarginals**【151】。然而，反方向却不总是成立：例如可以证明，存在着这样的边缘概率近似过程，任何的似然函数的导数都不与它对应【131,139】。

代理似然的主要优点是，拥有一个目标函数可以让该方法的特性易于理解——包括对人和对优化过程。先进的优化引擎，如共轭梯度和BFGS，需要一个目标函数来运行。另一方面，近似概率的优势则是更灵活。它易于与任何的推断算法相配合，包括一些技巧，如提前终止BP和MCMC。另外，近似概率方法与随机梯度框架匹配良好。

近似推断与参数估计的相互作用存在这一些无法完全理解的方面。Kulesza和Pereira【60】展示了一个例子，其中感知机算法与max-product置信传播之间有病态的相互作用。相反，代理似然方法不表现出这种病态，正如Wainwright【151】针对凸代理似然而指出的。

为了让讨论具体化，在本节的余下部分，我们讨论几个代理似然和近似概率方法的例子。我们基于伪似然（pseudolikelihood）（5.4.1节）和置信传播（5.4.2)来讨论代理似然方法，而基于置信传播（5.4.2）和MCMC（5.4.3）来讨论近似梯度方法。

###5.4.1伪似然

最早之一的代理似然是伪似然【9】。伪似然的想法是让训练目标只依赖于单一变量的条件分布。因为这些分布的归一化常数只依赖于单一变量，它们的计算变得十分有效率。在CRF这里，伪似然是
$$
\ell_{PL}=\sum_{s\in V}\log p(y_s|\pmb y_{N(s)},\pmb x\theta).(5.23)
$$
这里，求和运算要遍历图中所有的输出节点，而$$\pmb y_{N(s)}$$是$$Y_s$$邻域内的变量$$N(s)$$的值。（就像在式（5.8）中，我们不显式包含覆盖所有训练样本的求和）

直观地来理解伪似然，它试图让模型分布的局部条件分布$$p(y_s|\pmb y_{N(s)},\pmb x;\theta)$$匹配到训练数据上。又因为模型的条件独立假设，局部的条件分布就足以指明联合分布了。（这与Gibbs采样器背后的动因相似）

通过最大化伪似然来估计参数，即$$\hat{\theta}_{PL}=\max_{\theta}\ell_{PL}(\theta)$$。通常，最大化过程要使用像limited-memory BFGS的二阶方法，但在原理上，并行计算或随机梯度也可以像真似然那样用于伪似然。此外，也可以像极大似然那样使用规则化。

没有任何意味说明伪似然$$\ell_{PL}$$是一个对真似然的闭逼近（close approximation）。相反，是要让极大伪似然估计$$\hat{\theta}_{PL}$$逼近极大似然估计$$\hat{\theta}_{ML}$$。就是说，两个函数的值并不趋同，但它们的极值点趋同。在一些特定的条件下，尤其当模型空间正确时，可以表明，伪似然是渐进地正确的。就是说，当拥有无限多数据时，它将给出真实的参数。

伪似然背后的动因是计算效率。伪似然的计算和优化不用计算$$Z(\pmb x)$$和边缘分布。虽然伪似然有时在NLP上被证明有效【146】，但更多时候伪似然的性能槽糕【134】。直观地相当于，Gibbs采样器在序列模型中逐渐混淆。在视觉问题中，对伪似然常见的一个批评是说，“过于重视edge potentials了”【149】。一种直观的解释是说，用伪似然训练的模型学会了利用邻近变量的真值，但在测试时它们却不存在了。

可以采用块blockwise"版本的伪似然来提升性能。其中，局部项包含有模型中更大区域的条件概率。以线性链为例，人们可以考虑一种 per-edge 的伪似然：
$$
\ell_{EPL}(\theta)=\sum^{T-1}_{t=1}\log p(y_t,y_{t+1}|y_{t-1},y_{t+2},\theta).(5.24)
$$
(这里假定，我们的序列被虚标签$$y_0$$和$$y_{T+1}$$包围，已让上面的表达式正确）

块版本的伪似然是组合似然【34,75】的一个特例。在组合似然中，似然中的每一项不只预测了单一变量或成对变量，而是用户选择的任何尺寸的一块变量。组合似然扩展了标准的伪似然和块伪似然。关于组合似然估计的渐进一致性和正规性有一些理论结果。通常来说，大的块导致更好的参数估计——不管是理论上还是实践中。这带来了训练时间和结果参数质量之间的权衡。

最后，Sutton和McCallum的分段训练方法【134,137】与组合似然有关，但将其看作置信传播算法更易于理解，因而我们将它放到下一节。

### 5.4.2置信传播

循环置信传播算法（4.2.2节）可用于CRF的近似训练。这既可从伪似然的角度，也可从近似梯度的角度来完成。

在近似梯度算法中，在训练的每次迭代里，我们在训练输入$$\pmb x$$上运行循环BP，为模型的每个团产生一组近似的边缘概率$$q(\pmb {y}_c)$$。然后，我们把BP边缘概率带入，以近似真实梯度（5.9）。结果是近似的偏微分
$$
\frac{\partial \tilde{\ell}}{\partial \theta_{pk}}=\sum_{\Psi_c\in C_p}f_{pk}(\pmb x_c,\pmb y_c)-\sum_{\Psi_c\in C_p}\sum_{\pmb y'}f_{pk}(\pmb x_c,\pmb y'_c)q(\pmb y'_c). (5.25)
$$
这可以用来更新当前的参数：
$$
\theta^{(t+1)}_{pk}=\theta^{(t)}_{pk}+\alpha\frac{\partial\tilde{\ell}}{\partial \theta_{pk}},(5.26)
$$
其中，$$\alpha>0$$，是步长参数。这种方式的优点是它极其简单，尤其对一个外部的随机梯度近似法有用。

更有趣的是，在代理似然框架里也有使用循环BP的可能。我们需要给出真实似然（5.8）的一些代理函数，只要代理似然的梯度与近似BP梯度（5.26）相等。这看起来要求过高，然而幸运的是可以使用4.2.2节描述的Bethe free energy。

前面说过，循环置信传播可被看成一种优化算法。当关于所有的局部一致性置信向量上，最小化了目标函数$$\mathcal{O}_{BETHE}(q)$$，那么最小值$$\min_q\mathcal{O}(q)$$可被用来做归一化函数（partition function）的近似。把这一近似带入真似然（5.8），得到针对某个固定的置信向量$$q$$的近似似然：
$$
\ell_{BETHE}(\theta,q)=\sum_{C_p\in\mathcal{C}}\sum_{\Psi_c\in C_p}\log\Psi_c(\pmb x_c,\pmb y_c)-\sum_{C_p\in\mathcal{C}}\sum_{\Psi_c\in C_p}q(\pmb y_c)\log\frac{q(\pmb y_c)}{\Psi_c(\pmb x_c,\pmb y_c)}+\sum_{s\in Y}(1-d_i)q(y_s)\log q(y_s). (5.27)
$$
于是，近似训练可以被看成优化问题$$\max_{\theta}\min_q\ell_{BETHE}(\theta,q)$$。这是一个**鞍点问题saddlepoint problem**，关于一个变量最大化（去找最佳的参数）并关于其他最小化（去解近似推断问题）。一种解鞍点问题的方法是协调上升——交替地“固定$$\theta$$后关于$$q$$最小化$$\ell_{BETHE}$$“和”固定$$b$$<font color="red">原文如此</font>后关于$$\theta$$使用一个梯度更新来最大化$$\ell_{BETHE}$$。第一步就是运行循环BP算法。关键在于第二步，（5.27）关于权重$$\theta_k$$的偏导数正是（5.26）。这正是我们所需要的。

除此之外，也可以使用一个不同的代理似然，即
$$
\hat{\ell}(\theta;q)=\log\left[\frac{\prod_{C_p\in\mathcal{C}}\prod_{\Psi_c\in C_p}q(\pmb y_c)}{\prod_{s\in Y}q(y_s)^{d_s-1}}\right],(5.28）
$$
就是说，与其使用真的联合似然，不如把每个团的近似置信相乘，然后除以节点的置信to avoid overcounting。这样有一个好处——它是树结构模型的真似然的直接扩展。这可通过比较（5.28）和（4.32）看出。可以用我们在【91,94】上给出的Bethe energy的对偶版本来证明这一代理似然的正当性。当BP收敛，对于所得的置信向量$$q$$，可以看出$$\ell_{BETHE}(\theta,q)=\hat{\ell}(\theta,q)$$。这一等式并不总是成立，如当BP不收敛时。

另一种与BP相关的代理似然方法是**分片估计piecewise estimator**【137】。模型的因子被划分成易于操作的子图，并各自独立地训练。当局部特征的信息足够丰富时，这一方法意外地优秀（比 伪似然更好）。Sutton和Minka【139】讨论了分片训练与提前结束置信传播之间的紧密联系。

### 5.4.3 马尔科夫链蒙特卡洛

马尔科夫链蒙特卡洛（MCMC）推断方法（4.2.1）节可在近似边缘概率框架下用于CRF训练。一旦我们选择了一个马尔科夫链，其稳定分布为$$p(\pmb{y|x;\theta})$$，那么算法就是，运行多次迭代，然后用所得的近似边缘概率$$\hat{p}(\pmb{y|x;\theta})$$来近似梯度（5.9）式的真边缘概率。

实践中，MCMC方法却不怎么常用于CRF，因为MCMC方法通常需要多次迭代才收敛，而我们已经指出，训练过程需要反复运行推断任务。

解决这一难点的方法之一是对照散度（contrastive divergence ?)（CD）【50】。其中，式（5,9)中的真边缘概率$$p(y_c|\pmb{x})$$被只少量迭代的MCMC近似，而马尔科夫链的初始状态（就是$$\pmb y$$的值）被设置成训练数据中的值。CD主要用于潜变量模型，如受限波尔茨曼机。尽管在原理上CD也适用于CRF，但我们没有看到关于此的多少工作。

另一种可能是一种更加新的方法，叫做SampleRanke【155】，whose objective is that the learned parameters score paris of $$\pmb y_s$$ such that their sorted ranking obeys a given supervised ranking（通常被指定为某个固定的、将$$\pmb y$$与真实目标$$\pmb y$$进行比较的打分函数）。可通过MCMC采样器的序列状态 对 来计算 梯度的近似。就像CD，SampleRank在每个MCMC步中执行参数更新，而不去等马尔科夫链收敛。实验表明，SampleRank训练的模型的精度比CD有质的提升【155】。

与近似边缘概率框架不同，将MCMC推断用在代理似然框架则十分困难，因为从所周知地，很难从MCMC方法的样本中获得$$\log Z(\pmb x)$$的好的估计。

## 5.5 Implementation Concerns

<font color="red">

不翻译余下的部分了。尽管这本教材对我的帮助极大，但我仍认为它废话太多了。争取后面自己写一篇，期望能给读者一些简单明了、或多或少的帮助吧。

</font>











