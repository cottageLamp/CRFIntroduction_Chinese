# 2 建模

本章，我们从建模的角度来描述CRFs，阐述了CRF是如何把机构化的输出表示成高维输入向量的分布。可以把CRFs理解成，将逻辑回归分类器扩展到任意的图模型，也可以被理解成生成模型(如隐马尔科夫模型)的判别对应物。<font color=red>译注：**判别**和**生成**模型是两种在理论上等价(可互相推导得到对方)，但建模思路相反的模型</font>。

我们从对图模型的简单介绍(第2.1节)，以及对NLP中的生成和判别模型的介绍(第2.2节)开始。然后，我们可以给出了CRF的正式定义，包括常用的线性链(linear chains)(第2.3节)，以及通用图结构(第2.4节)。因为CRF的准确性严重依赖于所使用的特征，我们也描述了特征工程常用的一些技巧(第2.5节)。最后，我们提供两个CRF应用的例子(第2.6节)，以及一个宽泛的、关于CRFs应用领域的报告。

## 2.1 图模型

图模型是表达和推断多元概率分布的强大框架。它已经在统计模型的许多领域被证明有用，包括编码理论(coding theory)，计算机视觉，知识表达(knowledge representation)，贝叶斯统计(Bayesian statistics)，以及自然语言处理。

直接描述包含许多变量的分布，其代价是昂贵的。假如我们用表(table)来描述n个二值变量的联合分布，需要$$O(2^n)$$个浮点数(建议读者理解一下：每个变量有2种可能的取值，而总共有n个变量，那么总共有$$2^n$$种可能的取值。它这里的意思是：给每种取值赋予一个浮点数，表示其概率)。从图模型的角度看，认为一个分布尽管建立在许多变量之上，但常常可以表示成一些局部方程(local functions)的乘积，而这些方程只依赖于少量的变量。这种分解实际上与变量间的某些条件独立性密切相关——两种信息被轻易地用途来概括。实质上，分解、条件独立与图的结构，这三者构成了图模型框架力量的来源：条件独立性视角主要用于设计模型，而分解视角主要用于设计推断算法。

在本节的余下部分，我们从以上两个视角来介绍图模型，关注那些建立在无向图(undirected graphs\)之上的模型。关于更详细、更现代的图模型及其推断算法，可参考Koller 和 Friedman 【57】的教材。

### 2.1.1 无向图

我们考虑随机变量集合$$Y$$上的概率分布。我们通过整数$$s\in 1,2, \cdots |Y|$$来对变量进行索引。每个变量$$Y_s\in Y$$的取值范围都是集合$$\mathcal{Y}$$。本文我们只考虑离散的$$\mathcal{Y}$$，尽管它也可以是连续的。$$Y$$的一次特定的取值记做$${y}_s$$。对于$$Y$$中的特定变量$$Y_s$$，$${y}_s$$包含了对它的赋值，记做$$y_s$$。记号$${1}_{\{y=y'\}}$$表示一个函数，在$$y=y'$$时取1，而在其他时候取0。我们还需要边缘分布的记号。对于某个固定的取值$$y_s$$，我们用求和符号  $$\sum_{y \backslash y_s}$$来表示:：在$${y}$$的全部取值中，那些$$Y_s=y_s$$的取值的概率的和。

假定，我们相信一个概率分布$$p$$可以表示成一组因子，记做$$\Psi(y_a)$$的连乘。其中，a是一个整数索引(下标)，从1变化到A，而A就是因子的个数。每个因子$$\Psi(y_a)$$只依赖于部分变量$$Y_a\in Y$$。$$\Psi(y_a)$$是一个非负数，可以被看成$$y_a$$的自洽性的度量。自洽性高的取值，其发生的概率就高。这种分解让我们更高效地表示分布$$p$$，因为集合$$Y_a$$要比完整的集合$$Y$$小得多。

一个无向图模型是这样一种概率分布，它根据一组给定的因子来分解模型。正式地，给定$$Y$$的子集$$\{Y_a\}^A_{a=1}$$的集合，一个无向图模型是所有可以写成下式的分布：

$$
p(y)=\frac{1}{Z}\prod^A_{a=1} \Psi({y}_a) (2.1)
$$

其中，对于任意的因子$$\mathcal{F}=\{\Psi(y_a)\}$$，及其对应的所有可能的$$y_a$$，都有$$\Psi(y_a)\geq0$$。(这些因子又被称作**局部函数**或**自洽性函数**。)我们将用**随机场**来表示由某个无向图定义的特定分布。常数$$Z$$是一个归一化因子，保证分布$$p$$的和为1。它定义如下：

$$
Z=\sum_y \prod^A_{a=1}\Psi(y_a) (2.2)
$$


Z的值，考虑成因子集合$$\mathcal{F}$$的函数的话，也被称作**配分函数(partition function)**。注意，式(2.2)中的求和，需要在爆炸式的$$ y$$的所有可能取值上进行。因此，计算Z通常是不可行的，但是有很多关于估计它的研究(见第4章)。

术语“图模型”的来由，在于式(2.1)所表示的因子分解，可以建紧凑地表示成一张图。**因子图【58】**提供了一个特别自然的构图方法。一个因子图是一个两两连接图$$G=(V,F,E)$$。其中，节点的集合$$V=\{1,2,...,|Y|\}$$索引了模型中的全部随机变量，另一组节点的集合$$F=\{1,2,...,A\}$$索引了所有的因子。对图的理解是：如果一个变量节点s连接到一个因子节点a，那么在模型中，变量$$Y_s$$就是因子$$\Psi_a$$的一个参数。所以，因子图直接描述了，一个分布是如何被分解成多一个局部函数的乘积的。

我们正式地定义——一个因子图是否“描述”了一个分布？记$$N(a)$$包含了所有连接到因子节点a上的变量节点，那么：

------

**定义2.1** 仅当存在一组局部方程$$\Psi(y_a)$$，使得$$p$$可以写成：

$$p(y)=Z^{-1}\prod_{a\in F}\Psi(y_{N(a)}) (2.3)$$

时，一个分布$$p(y)$$根据因子图$$G$$分解了。

------

一组子集描述了无向模型，而一个因子图同样如此。在式(2.1)中，取子集为节点的邻居$$\{Y_N(a)|\forall a  \in F\}$$。根据式(2.1)定义的无向图模型，对应着所有根据$$G$$进行分解所得的分布。

![](/assets/2.1.png)

图2.1 带3个变量的因子图

图2.1展示了一个带有3个随机变量的因子图，图中，圆圈是变量节点，而灰色方块是因子节点。我们根据节点的索引进行了标注。这个因子图能够描述所有的带3个变量的分布，前提是对于任意的$$y=(y_1,y_2,y_3)$$，该分布能够写成$$p(y_1,y_2,y_3)=\Psi_1(y_1,y_2)\Psi_2(y_2,y_3)\Psi_3(y_1,y_3)$$的形式。

图模型的因子分解与变量间(在其取值范围里)的条件独立性密切相关。这种联系可通过另一种无向图来理解——马尔科夫网。它直接描述了多元分布的条件独立关系。马尔科夫网只是随机变量的图，不包括因子。现记$$G$$为整数序列$$V=\{1,2,...,|Y|\}$$上的无向图，而$$V$$仍是随机变量的索引。对于某一个索引$$s$$，记$$N(S)$$为它的邻居。那么我们称$$p$$是关于$$G$$的马尔科夫网，仅当它满足局部的马尔科夫特性：对于任意的两个变量$$Y_s,Y_t\in Y$$，$$Y_s$$关于它的邻居独立于$$Y_t$$。




