# 5.4 近似训练

我们所描述过的训练方法，包括随机和并行梯度方法，都假定易处理的图结构。就是说，我们可以有效地计算归一化函数$$Z( x)$$和边缘分布$$p( y_c| x)$$。这对线性链和树形结构CRF是有效的。早期的CRF关注于它们，即是因为它们的推断易于完成，也因为它们很自然地适合一些任务，如NLP中的序列标注任务。

当图的结构更复杂时，边缘分布和归一化函数都不是易于计算的，使我们必须凭借近似手段。如地4节所说的，存在着大量的近似推断算法。在讨论CRF时，却有一个需要进一步考虑的关键问题——近似推断被嵌入到更大的参数优化过程里。

有两个通用的近似训练CRF的策略【139】：**代理似然surrogate likelihood**策略(通过修改目标函数)和**近似边缘概率approximate marginals**策略(通过近似梯度)。第一种策略要寻找$$\ell(\theta)$$的替代者(就像BP近似(5.27))，被称作代理似然。它需是易于计算的同时，仍偏爱着好的参数。然后用基于梯度的方法来优化这一代理似然，就像真实似然一样。近似边缘策略使用通用的推断算法来计算边缘$$p(y_c| x)$$的近似，然后在式(5.9)中用近似概率替代精确概率，再用这一近似梯度来完成梯度下降过程。

虽然代理似然和近似边缘概率方法紧密相关，但却是不同的。通常一个代理似然方法直接产生一个近似概率方法，因为就像$$\log Z( x)$$的导数给出了真实的边缘概率，近似的$$\log Z( x)$$也可以看成是边缘概率的近似。这些近似的边缘概率有时被称为**pseudomarginals**【151】。然而，反方向却不总是成立：例如可以证明，存在着这样的边缘概率近似过程，任何的似然函数的导数都不与它对应【131,139】。

代理似然的主要优点是，拥有一个目标函数可以让该方法的特性易于理解——包括对人和对优化过程。先进的优化引擎，如共轭梯度和BFGS，需要一个目标函数来运行。另一方面，近似概率的优势则是更灵活。它易于与任何的推断算法相配合，包括一些技巧，如提前终止BP和MCMC。另外，近似概率方法与随机梯度框架匹配良好。

近似推断与参数估计的相互作用存在这一些无法完全理解的方面。Kulesza和Pereira【60】展示了一个例子，其中感知机算法与max-product置信传播之间有病态的相互作用。相反，代理似然方法不表现出这种病态，正如Wainwright【151】针对凸代理似然而指出的。

为了让讨论具体化，在本节的余下部分，我们讨论几个代理似然和近似概率方法的例子。我们基于伪似然(pseudolikelihood)(5.4.1节)和置信传播(5.4.2)来讨论代理似然方法，而基于置信传播(5.4.2)和MCMC(5.4.3)来讨论近似梯度方法。

## 5.4.1 伪似然

最早之一的代理似然是伪似然【9】。伪似然的想法是让训练目标只依赖于单一变量的条件分布。因为这些分布的归一化常数只依赖于单一变量，它们的计算变得十分有效率。在CRF这里，伪似然是

$$
\ell_{PL}=\sum_{s\in V}\log p(y_s| y_{N(s)}, x\theta) (5.23)
$$

这里，求和运算要遍历图中所有的输出节点，而$$ y_{N(s)}$$是$$Y_s$$邻域内的变量N(s)的值。(就像在式(5.8)中，我们不显式包含覆盖所有训练样本的求和)

直观地来理解伪似然，它试图让模型分布的局部条件分布$$p(y_s|y_{N(s)}, x;\theta)$$匹配到训练数据上。又因为模型的条件独立假设，局部的条件分布就足以指明联合分布了。(这与Gibbs采样器背后的动因相似)

通过最大化伪似然来估计参数，即$$\hat{\theta}_{PL}=\max_{\theta}\ell_{PL}(\theta)$$。通常，最大化过程要使用像limited-memory BFGS的二阶方法，但在原理上，并行计算或随机梯度也可以像真似然那样用于伪似然。此外，也可以像极大似然那样使用规则化。

没有任何意味说明伪似然$$\ell_{PL}$$是一个对真似然的闭逼近(close approximation)。相反，是要让极大伪似然估计$$\hat{\theta}_{PL}$$逼近极大似然估计$$\hat{\theta}_{ML}$$。就是说，两个函数的值并不趋同，但它们的极值点趋同。在一些特定的条件下，尤其当模型空间正确时，可以表明，伪似然是渐进地正确的。就是说，当拥有无限多数据时，它将给出真实的参数。

伪似然背后的动因是计算效率。伪似然的计算和优化不用计算$$Z( x)$$和边缘分布。虽然伪似然有时在NLP上被证明有效【146】，但更多时候伪似然的性能槽糕【134】。直观地相当于，Gibbs采样器在序列模型中逐渐混淆。在视觉问题中，对伪似然常见的一个批评是说，“过于重视edge potentials了”【149】。一种直观的解释是说，用伪似然训练的模型学会了利用邻近变量的真值，但在测试时它们却不存在了。

可以采用块blockwise"版本的伪似然来提升性能。其中，局部项包含有模型中更大区域的条件概率。以线性链为例，人们可以考虑一种 per-edge 的伪似然：

$$
\ell_{EPL}(\theta)=\sum^{T-1}_{t=1}\log p(y_t,y_{t+1}|y_{t-1},y_{t+2},\theta) (5.24)
$$

(这里假定，我们的序列被虚标签$$y_0$$和$$y_{T+1}$$包围，已让上面的表达式正确)

块版本的伪似然是组合似然【34,75】的一个特例。在组合似然中，似然中的每一项不只预测了单一变量或成对变量，而是用户选择的任何尺寸的一块变量。组合似然扩展了标准的伪似然和块伪似然。关于组合似然估计的渐进一致性和正规性有一些理论结果。通常来说，大的块导致更好的参数估计——不管是理论上还是实践中。这带来了训练时间和结果参数质量之间的权衡。

最后，Sutton和McCallum的分段训练方法【134,137】与组合似然有关，但将其看作置信传播算法更易于理解，因而我们将它放到下一节。

## 5.4.2置信传播

循环置信传播算法(4.2.2节)可用于CRF的近似训练。这既可从伪似然的角度，也可从近似梯度的角度来完成。

在近似梯度算法中，在训练的每次迭代里，我们在训练输入x上运行循环BP，为模型的每个团产生一组近似的边缘概率$$q( y_c)$$。然后，我们把BP边缘概率带入，以近似真实梯度(5.9)。结果是近似的偏微分

$$
\frac{\partial \tilde{\ell}}{\partial \theta_{pk}}=\sum_{\Psi_c\in C_p}f_{pk}(x_c, y_c)-\sum_{\Psi_c\in C_p}\sum_{y'}f_{pk}(x_c, y'_c)q( y'_c) (5.25)
$$

这可以用来更新当前的参数：

$$
\theta^{(t+1)}_{pk}=\theta^{(t)}_{pk}+\alpha\frac{\partial\tilde{\ell}}{\partial \theta_{pk}} (5.26)
$$

其中，$$\alpha>0$$，是步长参数。这种方式的优点是它极其简单，尤其对一个外部的随机梯度近似法有用。

更有趣的是，在代理似然框架里也有使用循环BP的可能。我们需要给出真实似然(5.8)的一些代理函数，只要代理似然的梯度与近似BP梯度(5.26)相等。这看起来要求过高，然而幸运的是可以使用4.2.2节描述的Bethe free energy。

前面说过，循环置信传播可被看成一种优化算法。当关于所有的局部一致性置信向量上，最小化了目标函数$$\mathcal{O}_{BETHE}(q)$$，那么最小值$$\min_q\mathcal{O}(q)$$可被用来做归一化函数(partition function)的近似。把这一近似带入真似然(5.8)，得到针对某个固定的置信向量$$q$$的近似似然：

$$
\ell_{BETHE}(\theta,q)=\sum_{C_p\in\mathcal{C}}\sum_{\Psi_c\in C_p}\log\Psi_c( x_c, y_c)-\sum_{C_p\in\mathcal{C}}\sum_{\Psi_c\in C_p}q( y_c)\log\frac{q( y_c)}{\Psi_c( x_c, y_c)}+\sum_{s\in Y}(1-d_i)q(y_s)\log q(y_s). (5.27)
$$

于是，近似训练可以被看成优化问题$$\max_{\theta}\min_q\ell_{BETHE}(\theta,q)$$。这是一个**鞍点问题saddlepoint problem**，关于一个变量最大化(去找最佳的参数)并关于其他最小化(去解近似推断问题)。一种解鞍点问题的方法是协调上升——交替地“固定$$\theta$$后关于q最小化$$\ell_{BETHE}$$“和”固定b<font color="red">原文如此</font>后关于$$\theta$$使用一个梯度更新来最大化$$\ell_{BETHE}$$。第一步就是运行循环BP算法。关键在于第二步，(5.27)关于权重$$\theta_k$$的偏导数正是(5.26)。这正是我们所需要的。

除此之外，也可以使用一个不同的代理似然，即

$$
\hat{\ell}(\theta;q)=\log\left[\frac{\prod_{C_p\in\mathcal{C}}\prod_{\Psi_c\in C_p}q( y_c)}{\prod_{s\in Y}q(y_s)^{d_s-1}}\right] (5.28)
$$

就是说，与其使用真的联合似然，不如把每个团的近似置信相乘，然后除以节点的置信to avoid overcounting。这样有一个好处——它是树结构模型的真似然的直接扩展。这可通过比较(5.28)和(4.32)看出。可以用我们在【91,94】上给出的Bethe energy的对偶版本来证明这一代理似然的正当性。当BP收敛，对于所得的置信向量q，可以看出$$\ell_{BETHE}(\theta,q)=\hat{\ell}(\theta,q)$$。这一等式并不总是成立，如当BP不收敛时。

另一种与BP相关的代理似然方法是**分片估计piecewise estimator**【137】。模型的因子被划分成易于操作的子图，并各自独立地训练。当局部特征的信息足够丰富时，这一方法意外地优秀(比 伪似然更好)。Sutton和Minka【139】讨论了分片训练与提前结束置信传播之间的紧密联系。

## 5.4.3 马尔科夫链蒙特卡洛

马尔科夫链蒙特卡洛(MCMC)推断方法(4.2.1)节可在近似边缘概率框架下用于CRF训练。一旦我们选择了一个马尔科夫链，其稳定分布为$$p({y|x;\theta})$$，那么算法就是，运行多次迭代，然后用所得的近似边缘概率$$\hat{p}({y|x;\theta})$$来近似梯度(5.9)式的真边缘概率。

实践中，MCMC方法却不怎么常用于CRF，因为MCMC方法通常需要多次迭代才收敛，而我们已经指出，训练过程需要反复运行推断任务。

解决这一难点的方法之一是对照散度(contrastive divergence?)(CD)【50】。其中，式(5,9)中的真边缘概率$$p(y_c|x)$$被只少量迭代的MCMC近似，而马尔科夫链的初始状态(就是y的值)被设置成训练数据中的值。CD主要用于潜变量模型，如受限波尔茨曼机。尽管在原理上CD也适用于CRF，但我们没有看到关于此的多少工作。

另一种可能是一种更加新的方法，叫做SampleRanke【155】，whose objective is that the learned parameters score paris of $$y_s$$ such that their sorted ranking obeys a given supervised ranking(通常被指定为某个固定的、将y与真实目标y进行比较的打分函数)。可通过MCMC采样器的序列状态对来计算梯度的近似。就像CD，SampleRank在每个MCMC步中执行参数更新，而不去等马尔科夫链收敛。实验表明，SampleRank训练的模型的精度比CD有质的提升【155】。

与近似边缘概率框架不同，将MCMC推断用在代理似然框架则十分困难，因为从所周知地，很难从MCMC方法的样本中获得$$\log Z(x)$$的好的估计。